{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Genetic algorithm for hyperparameter tuning of a deep Neural Network using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import operator\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=5, n_neurons=100, name=None,\n",
    "        activation=tf.nn.elu, initializer=he_init):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_outputs = 5\n",
    "\n",
    "#reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images[mnist.train.labels < 5]\n",
    "y_train1 = mnist.train.labels[mnist.train.labels < 5]\n",
    "X_valid1 = mnist.validation.images[mnist.validation.labels < 5]\n",
    "y_valid1 = mnist.validation.labels[mnist.validation.labels < 5]\n",
    "X_test1 = mnist.test.images[mnist.test.labels < 5]\n",
    "y_test1 = mnist.test.labels[mnist.test.labels < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.123383\tBest loss: 0.123383\tAccuracy: 97.11%\n",
      "1\tValidation loss: 0.177884\tBest loss: 0.123383\tAccuracy: 95.19%\n",
      "2\tValidation loss: 0.109575\tBest loss: 0.109575\tAccuracy: 97.97%\n",
      "3\tValidation loss: 0.092251\tBest loss: 0.092251\tAccuracy: 97.62%\n",
      "4\tValidation loss: 2.287983\tBest loss: 0.092251\tAccuracy: 70.76%\n",
      "5\tValidation loss: 0.681341\tBest loss: 0.092251\tAccuracy: 77.80%\n",
      "6\tValidation loss: 1.424878\tBest loss: 0.092251\tAccuracy: 57.08%\n",
      "7\tValidation loss: 1.636677\tBest loss: 0.092251\tAccuracy: 18.73%\n",
      "8\tValidation loss: 1.707939\tBest loss: 0.092251\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.626957\tBest loss: 0.092251\tAccuracy: 18.73%\n",
      "10\tValidation loss: 1.623782\tBest loss: 0.092251\tAccuracy: 19.08%\n",
      "11\tValidation loss: 1.680743\tBest loss: 0.092251\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.697856\tBest loss: 0.092251\tAccuracy: 20.91%\n",
      "13\tValidation loss: 1.626846\tBest loss: 0.092251\tAccuracy: 19.08%\n",
      "14\tValidation loss: 1.661726\tBest loss: 0.092251\tAccuracy: 18.73%\n",
      "15\tValidation loss: 1.626308\tBest loss: 0.092251\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.638750\tBest loss: 0.092251\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.844580\tBest loss: 0.092251\tAccuracy: 19.27%\n",
      "18\tValidation loss: 1.702606\tBest loss: 0.092251\tAccuracy: 20.91%\n",
      "19\tValidation loss: 1.744452\tBest loss: 0.092251\tAccuracy: 20.91%\n",
      "20\tValidation loss: 1.640063\tBest loss: 0.092251\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.741046\tBest loss: 0.092251\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.835398\tBest loss: 0.092251\tAccuracy: 22.01%\n",
      "23\tValidation loss: 1.748770\tBest loss: 0.092251\tAccuracy: 18.73%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy: 98.09%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 10\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "            # extra ops for batch normalization\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.190826\tBest loss: 0.190826\tAccuracy: 96.64%\n",
      "1\tValidation loss: 1.689649\tBest loss: 0.190826\tAccuracy: 18.73%\n",
      "2\tValidation loss: 1.660114\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "3\tValidation loss: 1.778077\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "4\tValidation loss: 1.667106\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "5\tValidation loss: 1.654532\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "6\tValidation loss: 1.680933\tBest loss: 0.190826\tAccuracy: 18.73%\n",
      "7\tValidation loss: 1.779077\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "8\tValidation loss: 1.699482\tBest loss: 0.190826\tAccuracy: 19.27%\n",
      "9\tValidation loss: 1.767771\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "10\tValidation loss: 1.629350\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.812643\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "12\tValidation loss: 1.675939\tBest loss: 0.190826\tAccuracy: 18.73%\n",
      "13\tValidation loss: 1.633259\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "14\tValidation loss: 1.652904\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "15\tValidation loss: 1.635943\tBest loss: 0.190826\tAccuracy: 20.91%\n",
      "16\tValidation loss: 1.718915\tBest loss: 0.190826\tAccuracy: 19.08%\n",
      "17\tValidation loss: 1.682456\tBest loss: 0.190826\tAccuracy: 19.27%\n",
      "18\tValidation loss: 1.675366\tBest loss: 0.190826\tAccuracy: 18.73%\n",
      "19\tValidation loss: 1.645805\tBest loss: 0.190826\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.722336\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.656422\tBest loss: 0.190826\tAccuracy: 22.01%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x00000143F62CC400>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x00000143F8607D08>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(random_state=42)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97081144191476942"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef getCost(n_hidden_layers, n_neurons, optimizer_class,\\n                 learning_rate, batch_size, activation, initializer,\\n                 batch_norm_momentum, dropout_rate, random_state,\\n                   X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test_1,n_epochs):\\n    \\n    \\n    \\n    dnn_clf = DNNClassifier(n_hidden_layers, n_neurons, optimizer_class,\\n                 learning_rate, batch_size, activation, initializer,\\n                 batch_norm_momentum, dropout_rate, random_state)\\n    dnn_clf.fit(X_train1, y_train1, n_epochs, X_valid=X_valid1, y_valid=y_valid1)\\n    \\n    y_pred = dnn_clf.predict(X_test1)\\n    return accuracy_score(y_test1, y_pred)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def getCost(n_hidden_layers, n_neurons, optimizer_class,\n",
    "                 learning_rate, batch_size, activation, initializer,\n",
    "                 batch_norm_momentum, dropout_rate, random_state,\n",
    "                   X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1,n_epochs):\n",
    "    \n",
    "    \n",
    "    \n",
    "    dnn_clf = DNNClassifier(n_hidden_layers, n_neurons, optimizer_class,\n",
    "                 learning_rate, batch_size, activation, initializer,\n",
    "                 batch_norm_momentum, dropout_rate, random_state)\n",
    "    dnn_clf.fit(X_train1, y_train1, n_epochs, X_valid=X_valid1, y_valid=y_valid1)\n",
    "    \n",
    "    y_pred = dnn_clf.predict(X_test1)\n",
    "    return accuracy_score(y_test1, y_pred)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#FOr running randomized algo\\n#rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\\n                                fit_params={\"X_valid\": X_valid1, \"y_valid\": y_valid1, \"n_epochs\": 1000},\\n                                random_state=42, verbose=2)\\n#rnd_search.fit(X_train1, y_train1)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import Randomize-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom deap import base, creator, tools, algorithms\\nfrom scipy.stats import bernoulli\\n\\npopulation_size = 4\\nnum_generations = 4\\ngene_length = 10\\nparams={'n_hidden_layers':[15,20],'n_neurons':[10,20]}\\n\\n# As we are trying to minimize the RMSE score, that's why using -1.0. \\n# In case, when you want to maximize accuracy for instance, use 1.0\\ncreator.create('FitnessMax', base.Fitness, weights = (1.0,))\\ncreator.create('Individual', list , fitness = creator.FitnessMax)\\n\\ntoolbox = base.Toolbox()\\ntoolbox.register('binary', bernoulli.rvs, 0.5)\\ntoolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, \\nn = gene_length)\\ntoolbox.register('population', tools.initRepeat, list , toolbox.individual)\\n\\ntoolbox.register('mate', tools.cxOrdered)\\ntoolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\\ntoolbox.register('select', tools.selRoulette)\\ntoolbox.register('evaluate', getCost,X_train1,y_train1,X_valid1,y_valid1,X_test1,y_test1,params)\\n\\npopulation = toolbox.population(n = population_size)\\nr = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, \\nngen = num_generations, verbose = False)\\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "population_size = 4\n",
    "num_generations = 4\n",
    "gene_length = 10\n",
    "params={'n_hidden_layers':[15,20],'n_neurons':[10,20]}\n",
    "\n",
    "# As we are trying to minimize the RMSE score, that's why using -1.0. \n",
    "# In case, when you want to maximize accuracy for instance, use 1.0\n",
    "creator.create('FitnessMax', base.Fitness, weights = (1.0,))\n",
    "creator.create('Individual', list , fitness = creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('binary', bernoulli.rvs, 0.5)\n",
    "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, \n",
    "n = gene_length)\n",
    "toolbox.register('population', tools.initRepeat, list , toolbox.individual)\n",
    "\n",
    "toolbox.register('mate', tools.cxOrdered)\n",
    "toolbox.register('mutate', tools.mutShuffleIndexes, indpb = 0.6)\n",
    "toolbox.register('select', tools.selRoulette)\n",
    "toolbox.register('evaluate', getCost,X_train1,y_train1,X_valid1,y_valid1,X_test1,y_test1,params)\n",
    "\n",
    "population = toolbox.population(n = population_size)\n",
    "r = algorithms.eaSimple(population, toolbox, cxpb = 0.4, mutpb = 0.1, \n",
    "ngen = num_generations, verbose = False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#genetic algorithm implementation\n",
    "generations=10\n",
    "\n",
    "\n",
    "param={'n_hidden_layers':[5,10,15,20],'n_neurons':[10,20,30,15],'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateRandomParams(param):\n",
    "    param_list=[]\n",
    "    for k,v in param_dict.items():\n",
    "        rnd=np.random.randint(0,len(v))\n",
    "        param_list.append(v[rnd])\n",
    "        \n",
    "    return param_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_list=generateRandomParams(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCost(X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1,param_list):\n",
    "    \n",
    "    \n",
    "    n_hidden_layers=param_list[0]\n",
    "    n_neurons=param_list[1]\n",
    "    learning_rate=param_list=[2]\n",
    "    \n",
    "    dnn_clf = DNNClassifier(n_hidden_layers, n_neurons)\n",
    "    dnn_clf.fit(X_train1, y_train1, n_epochs, X_valid=X_valid1, y_valid=y_valid1)\n",
    "    \n",
    "    y_pred = dnn_clf.predict(X_test1)\n",
    "    return accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.271155\tBest loss: 0.271155\tAccuracy: 92.77%\n",
      "1\tValidation loss: 0.213727\tBest loss: 0.213727\tAccuracy: 94.57%\n",
      "2\tValidation loss: 0.391432\tBest loss: 0.213727\tAccuracy: 91.95%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-11abd72d2a9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetCost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-160-06b374f92af4>\u001b[0m in \u001b[0;36mgetCost\u001b[1;34m(X_train1, y_train1, X_valid1, y_valid1, X_test1, y_test1, param_list)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdnn_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDNNClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_hidden_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mdnn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_valid1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_valid1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdnn_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-2d1eb2eecd06>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, n_epochs, X_valid, y_valid)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mrnd_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mrnd_indices\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnd_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                     \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrnd_indices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m                     \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_training\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "getCost(X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1,param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates  a dictionary having values in descending order\n",
    "def getTop_N_Fit(population):\n",
    "    fitness_dict={}\n",
    "    for i in range(population):\n",
    "        param_list=generateRandomParams(param)\n",
    "        #param_dict[i]=param_list\n",
    "        fitness=getCost(X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1,param_list)\n",
    "        fitness_dict[i]=(fitness,param_list)\n",
    "        \n",
    "    sorted_fitness_dict = dict(sorted(fitness_dict.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    return sorted_fitness_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.154623\tBest loss: 0.154623\tAccuracy: 96.17%\n",
      "1\tValidation loss: 0.364906\tBest loss: 0.154623\tAccuracy: 90.11%\n",
      "2\tValidation loss: 0.288331\tBest loss: 0.154623\tAccuracy: 91.20%\n",
      "3\tValidation loss: 0.328568\tBest loss: 0.154623\tAccuracy: 89.87%\n",
      "4\tValidation loss: 0.352195\tBest loss: 0.154623\tAccuracy: 88.58%\n",
      "5\tValidation loss: 0.432648\tBest loss: 0.154623\tAccuracy: 86.83%\n",
      "6\tValidation loss: 0.254245\tBest loss: 0.154623\tAccuracy: 92.69%\n",
      "7\tValidation loss: 0.332493\tBest loss: 0.154623\tAccuracy: 91.83%\n",
      "8\tValidation loss: 0.423323\tBest loss: 0.154623\tAccuracy: 88.55%\n",
      "9\tValidation loss: 0.653812\tBest loss: 0.154623\tAccuracy: 77.99%\n",
      "10\tValidation loss: 0.612142\tBest loss: 0.154623\tAccuracy: 78.69%\n",
      "11\tValidation loss: 0.710610\tBest loss: 0.154623\tAccuracy: 68.76%\n",
      "12\tValidation loss: 0.536184\tBest loss: 0.154623\tAccuracy: 82.21%\n",
      "13\tValidation loss: 0.329499\tBest loss: 0.154623\tAccuracy: 90.93%\n",
      "14\tValidation loss: 0.332647\tBest loss: 0.154623\tAccuracy: 91.95%\n",
      "15\tValidation loss: 0.486775\tBest loss: 0.154623\tAccuracy: 85.81%\n",
      "16\tValidation loss: 0.344947\tBest loss: 0.154623\tAccuracy: 91.24%\n",
      "17\tValidation loss: 0.309344\tBest loss: 0.154623\tAccuracy: 92.96%\n",
      "18\tValidation loss: 0.343494\tBest loss: 0.154623\tAccuracy: 90.81%\n",
      "19\tValidation loss: 0.297411\tBest loss: 0.154623\tAccuracy: 92.26%\n",
      "20\tValidation loss: 0.273222\tBest loss: 0.154623\tAccuracy: 93.55%\n",
      "21\tValidation loss: 0.270847\tBest loss: 0.154623\tAccuracy: 93.12%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.291109\tBest loss: 0.291109\tAccuracy: 93.12%\n",
      "1\tValidation loss: 0.402906\tBest loss: 0.291109\tAccuracy: 85.73%\n",
      "2\tValidation loss: 0.223278\tBest loss: 0.223278\tAccuracy: 94.80%\n",
      "3\tValidation loss: 0.240137\tBest loss: 0.223278\tAccuracy: 93.24%\n",
      "4\tValidation loss: 0.217776\tBest loss: 0.217776\tAccuracy: 94.72%\n",
      "5\tValidation loss: 0.177162\tBest loss: 0.177162\tAccuracy: 95.93%\n",
      "6\tValidation loss: 0.155615\tBest loss: 0.155615\tAccuracy: 96.40%\n",
      "7\tValidation loss: 0.178440\tBest loss: 0.155615\tAccuracy: 96.01%\n",
      "8\tValidation loss: 0.222222\tBest loss: 0.155615\tAccuracy: 93.63%\n",
      "9\tValidation loss: 0.344893\tBest loss: 0.155615\tAccuracy: 90.58%\n",
      "10\tValidation loss: 0.240181\tBest loss: 0.155615\tAccuracy: 94.68%\n",
      "11\tValidation loss: 0.254894\tBest loss: 0.155615\tAccuracy: 93.20%\n",
      "12\tValidation loss: 0.516575\tBest loss: 0.155615\tAccuracy: 82.76%\n",
      "13\tValidation loss: 0.202157\tBest loss: 0.155615\tAccuracy: 95.19%\n",
      "14\tValidation loss: 0.191651\tBest loss: 0.155615\tAccuracy: 95.82%\n",
      "15\tValidation loss: 0.275524\tBest loss: 0.155615\tAccuracy: 91.24%\n",
      "16\tValidation loss: 0.246423\tBest loss: 0.155615\tAccuracy: 92.14%\n",
      "17\tValidation loss: 0.177436\tBest loss: 0.155615\tAccuracy: 95.93%\n",
      "18\tValidation loss: 0.153098\tBest loss: 0.153098\tAccuracy: 96.25%\n",
      "19\tValidation loss: 0.147124\tBest loss: 0.147124\tAccuracy: 96.40%\n",
      "20\tValidation loss: 0.137392\tBest loss: 0.137392\tAccuracy: 96.87%\n",
      "21\tValidation loss: 0.168916\tBest loss: 0.137392\tAccuracy: 96.48%\n",
      "22\tValidation loss: 0.438504\tBest loss: 0.137392\tAccuracy: 83.78%\n",
      "23\tValidation loss: 0.236117\tBest loss: 0.137392\tAccuracy: 95.23%\n",
      "24\tValidation loss: 0.202050\tBest loss: 0.137392\tAccuracy: 95.47%\n",
      "25\tValidation loss: 0.399360\tBest loss: 0.137392\tAccuracy: 85.61%\n",
      "26\tValidation loss: 0.296402\tBest loss: 0.137392\tAccuracy: 92.38%\n",
      "27\tValidation loss: 0.244481\tBest loss: 0.137392\tAccuracy: 93.94%\n",
      "28\tValidation loss: 0.254889\tBest loss: 0.137392\tAccuracy: 94.61%\n",
      "29\tValidation loss: 0.611847\tBest loss: 0.137392\tAccuracy: 78.15%\n",
      "30\tValidation loss: 0.245203\tBest loss: 0.137392\tAccuracy: 95.23%\n",
      "31\tValidation loss: 0.197185\tBest loss: 0.137392\tAccuracy: 96.01%\n",
      "32\tValidation loss: 0.247265\tBest loss: 0.137392\tAccuracy: 93.86%\n",
      "33\tValidation loss: 0.176416\tBest loss: 0.137392\tAccuracy: 95.15%\n",
      "34\tValidation loss: 0.201056\tBest loss: 0.137392\tAccuracy: 94.49%\n",
      "35\tValidation loss: 0.194690\tBest loss: 0.137392\tAccuracy: 95.31%\n",
      "36\tValidation loss: 0.260006\tBest loss: 0.137392\tAccuracy: 93.86%\n",
      "37\tValidation loss: 0.219727\tBest loss: 0.137392\tAccuracy: 95.27%\n",
      "38\tValidation loss: 0.226011\tBest loss: 0.137392\tAccuracy: 93.82%\n",
      "39\tValidation loss: 0.295778\tBest loss: 0.137392\tAccuracy: 91.79%\n",
      "40\tValidation loss: 0.282458\tBest loss: 0.137392\tAccuracy: 92.42%\n",
      "41\tValidation loss: 0.259694\tBest loss: 0.137392\tAccuracy: 93.75%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.258738\tBest loss: 0.258738\tAccuracy: 93.08%\n",
      "1\tValidation loss: 0.205829\tBest loss: 0.205829\tAccuracy: 94.96%\n",
      "2\tValidation loss: 0.398899\tBest loss: 0.205829\tAccuracy: 91.40%\n",
      "3\tValidation loss: 0.291192\tBest loss: 0.205829\tAccuracy: 94.14%\n",
      "4\tValidation loss: 0.528813\tBest loss: 0.205829\tAccuracy: 80.81%\n",
      "5\tValidation loss: 0.297956\tBest loss: 0.205829\tAccuracy: 92.38%\n",
      "6\tValidation loss: 0.273348\tBest loss: 0.205829\tAccuracy: 93.28%\n",
      "7\tValidation loss: 0.519106\tBest loss: 0.205829\tAccuracy: 84.48%\n",
      "8\tValidation loss: 0.327515\tBest loss: 0.205829\tAccuracy: 91.44%\n",
      "9\tValidation loss: 0.404121\tBest loss: 0.205829\tAccuracy: 86.75%\n",
      "10\tValidation loss: 0.338378\tBest loss: 0.205829\tAccuracy: 91.83%\n",
      "11\tValidation loss: 0.228083\tBest loss: 0.205829\tAccuracy: 95.39%\n",
      "12\tValidation loss: 0.251600\tBest loss: 0.205829\tAccuracy: 95.43%\n",
      "13\tValidation loss: 0.224582\tBest loss: 0.205829\tAccuracy: 95.97%\n",
      "14\tValidation loss: 0.223672\tBest loss: 0.205829\tAccuracy: 95.97%\n",
      "15\tValidation loss: 0.220866\tBest loss: 0.205829\tAccuracy: 96.21%\n",
      "16\tValidation loss: 0.214911\tBest loss: 0.205829\tAccuracy: 95.90%\n",
      "17\tValidation loss: 0.234478\tBest loss: 0.205829\tAccuracy: 95.43%\n",
      "18\tValidation loss: 0.224145\tBest loss: 0.205829\tAccuracy: 95.23%\n",
      "19\tValidation loss: 1.220571\tBest loss: 0.205829\tAccuracy: 37.14%\n",
      "20\tValidation loss: 1.618073\tBest loss: 0.205829\tAccuracy: 19.08%\n",
      "21\tValidation loss: 1.614126\tBest loss: 0.205829\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.612165\tBest loss: 0.205829\tAccuracy: 19.27%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.456566\tBest loss: 0.456566\tAccuracy: 77.52%\n",
      "1\tValidation loss: 0.482784\tBest loss: 0.456566\tAccuracy: 77.87%\n",
      "2\tValidation loss: 0.572279\tBest loss: 0.456566\tAccuracy: 76.19%\n",
      "3\tValidation loss: 0.462143\tBest loss: 0.456566\tAccuracy: 85.11%\n",
      "4\tValidation loss: 0.442073\tBest loss: 0.442073\tAccuracy: 83.66%\n",
      "5\tValidation loss: 0.297147\tBest loss: 0.297147\tAccuracy: 90.30%\n",
      "6\tValidation loss: 0.364368\tBest loss: 0.297147\tAccuracy: 89.91%\n",
      "7\tValidation loss: 0.335810\tBest loss: 0.297147\tAccuracy: 91.95%\n",
      "8\tValidation loss: 0.513398\tBest loss: 0.297147\tAccuracy: 73.38%\n",
      "9\tValidation loss: 0.304607\tBest loss: 0.297147\tAccuracy: 92.30%\n",
      "10\tValidation loss: 0.304019\tBest loss: 0.297147\tAccuracy: 93.59%\n",
      "11\tValidation loss: 0.309354\tBest loss: 0.297147\tAccuracy: 93.75%\n",
      "12\tValidation loss: 0.287273\tBest loss: 0.287273\tAccuracy: 93.94%\n",
      "13\tValidation loss: 0.410554\tBest loss: 0.287273\tAccuracy: 88.15%\n",
      "14\tValidation loss: 0.331514\tBest loss: 0.287273\tAccuracy: 92.18%\n",
      "15\tValidation loss: 0.321074\tBest loss: 0.287273\tAccuracy: 95.11%\n",
      "16\tValidation loss: 0.384808\tBest loss: 0.287273\tAccuracy: 89.33%\n",
      "17\tValidation loss: 0.351955\tBest loss: 0.287273\tAccuracy: 89.48%\n",
      "18\tValidation loss: 0.387604\tBest loss: 0.287273\tAccuracy: 87.96%\n",
      "19\tValidation loss: 0.450773\tBest loss: 0.287273\tAccuracy: 85.93%\n",
      "20\tValidation loss: 0.419601\tBest loss: 0.287273\tAccuracy: 85.69%\n",
      "21\tValidation loss: 0.322804\tBest loss: 0.287273\tAccuracy: 89.17%\n",
      "22\tValidation loss: 0.267194\tBest loss: 0.267194\tAccuracy: 94.18%\n",
      "23\tValidation loss: 0.246806\tBest loss: 0.246806\tAccuracy: 95.15%\n",
      "24\tValidation loss: 5.338128\tBest loss: 0.246806\tAccuracy: 94.14%\n",
      "25\tValidation loss: 0.262308\tBest loss: 0.246806\tAccuracy: 94.68%\n",
      "26\tValidation loss: 0.483225\tBest loss: 0.246806\tAccuracy: 92.46%\n",
      "27\tValidation loss: 0.297036\tBest loss: 0.246806\tAccuracy: 94.84%\n",
      "28\tValidation loss: 0.332040\tBest loss: 0.246806\tAccuracy: 92.73%\n",
      "29\tValidation loss: 0.278852\tBest loss: 0.246806\tAccuracy: 94.88%\n",
      "30\tValidation loss: 0.259783\tBest loss: 0.246806\tAccuracy: 94.61%\n",
      "31\tValidation loss: 0.271898\tBest loss: 0.246806\tAccuracy: 95.43%\n",
      "32\tValidation loss: 0.270832\tBest loss: 0.246806\tAccuracy: 95.93%\n",
      "33\tValidation loss: 0.229844\tBest loss: 0.229844\tAccuracy: 96.13%\n",
      "34\tValidation loss: 0.294593\tBest loss: 0.229844\tAccuracy: 94.14%\n",
      "35\tValidation loss: 0.259657\tBest loss: 0.229844\tAccuracy: 94.29%\n",
      "36\tValidation loss: 0.270040\tBest loss: 0.229844\tAccuracy: 95.86%\n",
      "37\tValidation loss: 1.027733\tBest loss: 0.229844\tAccuracy: 56.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\tValidation loss: 1.047998\tBest loss: 0.229844\tAccuracy: 57.94%\n",
      "39\tValidation loss: 0.785590\tBest loss: 0.229844\tAccuracy: 64.74%\n",
      "40\tValidation loss: 0.767029\tBest loss: 0.229844\tAccuracy: 64.35%\n",
      "41\tValidation loss: 0.781985\tBest loss: 0.229844\tAccuracy: 64.97%\n",
      "42\tValidation loss: 0.822877\tBest loss: 0.229844\tAccuracy: 59.34%\n",
      "43\tValidation loss: 0.855906\tBest loss: 0.229844\tAccuracy: 58.17%\n",
      "44\tValidation loss: 0.801427\tBest loss: 0.229844\tAccuracy: 59.27%\n",
      "45\tValidation loss: 0.788450\tBest loss: 0.229844\tAccuracy: 59.93%\n",
      "46\tValidation loss: 0.793331\tBest loss: 0.229844\tAccuracy: 59.03%\n",
      "47\tValidation loss: 0.807582\tBest loss: 0.229844\tAccuracy: 58.84%\n",
      "48\tValidation loss: 0.808173\tBest loss: 0.229844\tAccuracy: 58.37%\n",
      "49\tValidation loss: 0.821813\tBest loss: 0.229844\tAccuracy: 57.51%\n",
      "50\tValidation loss: 0.804727\tBest loss: 0.229844\tAccuracy: 58.72%\n",
      "51\tValidation loss: 0.746395\tBest loss: 0.229844\tAccuracy: 65.44%\n",
      "52\tValidation loss: 0.539769\tBest loss: 0.229844\tAccuracy: 77.80%\n",
      "53\tValidation loss: 0.354930\tBest loss: 0.229844\tAccuracy: 92.92%\n",
      "54\tValidation loss: 0.553078\tBest loss: 0.229844\tAccuracy: 74.51%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.190808\tBest loss: 0.190808\tAccuracy: 95.35%\n",
      "1\tValidation loss: 0.721201\tBest loss: 0.190808\tAccuracy: 76.78%\n",
      "2\tValidation loss: 0.572475\tBest loss: 0.190808\tAccuracy: 76.08%\n",
      "3\tValidation loss: 0.270803\tBest loss: 0.190808\tAccuracy: 93.16%\n",
      "4\tValidation loss: 0.196529\tBest loss: 0.190808\tAccuracy: 95.90%\n",
      "5\tValidation loss: 0.264434\tBest loss: 0.190808\tAccuracy: 94.25%\n",
      "6\tValidation loss: 1.615117\tBest loss: 0.190808\tAccuracy: 18.69%\n",
      "7\tValidation loss: 1.620957\tBest loss: 0.190808\tAccuracy: 22.01%\n",
      "8\tValidation loss: 1.613402\tBest loss: 0.190808\tAccuracy: 22.01%\n",
      "9\tValidation loss: 1.630868\tBest loss: 0.190808\tAccuracy: 18.73%\n",
      "10\tValidation loss: 1.632110\tBest loss: 0.190808\tAccuracy: 22.01%\n",
      "11\tValidation loss: 1.637514\tBest loss: 0.190808\tAccuracy: 18.73%\n",
      "12\tValidation loss: 1.655095\tBest loss: 0.190808\tAccuracy: 19.27%\n",
      "13\tValidation loss: 1.635908\tBest loss: 0.190808\tAccuracy: 19.08%\n",
      "14\tValidation loss: 1.631372\tBest loss: 0.190808\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.622916\tBest loss: 0.190808\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.645204\tBest loss: 0.190808\tAccuracy: 18.73%\n",
      "17\tValidation loss: 1.644993\tBest loss: 0.190808\tAccuracy: 19.08%\n",
      "18\tValidation loss: 1.633085\tBest loss: 0.190808\tAccuracy: 20.91%\n",
      "19\tValidation loss: 1.619056\tBest loss: 0.190808\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.621444\tBest loss: 0.190808\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.644150\tBest loss: 0.190808\tAccuracy: 19.27%\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "sorted_fitness_dict=getTop_N_Fit(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5, (9, [9, 5, 4])), (3, (4, [3, 4, 5, 6])), (4, (3, [9, 5, 4])), (1, (2, [1, 2, 3]))]\n"
     ]
    }
   ],
   "source": [
    "#x = {1: (2,[1,2,3]), 3: (4,[3,4,5,6]), 4: (3,[9,5,4]), 5: (9,[9,5,4])}\n",
    "#sorted_x = sorted(x.items(), key=lambda x:x[1],reverse=True)\n",
    "#print (sorted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.96516832068495817, [15, 10, 0.01]),\n",
       " 1: (0.97139521307647403, [15, 10, 0.1]),\n",
       " 2: (0.95913601868067722, [15, 20, 0.1]),\n",
       " 3: (0.96730881494454179, [20, 10, 0.1]),\n",
       " 4: (0.95835765713173771, [15, 20, 0.1])}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_fitness_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateChildren(sorted_fitness_dict,X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1):\n",
    "    \n",
    "    #Getting the last two keys of worst performing hyperparameters\n",
    "    key1=list(sorted_fitness_dict.keys())[-1]\n",
    "    key2=list(sorted_fitness_dict.keys())[-2]\n",
    "    \n",
    "    #print (key1)\n",
    "    \n",
    "    #getting parent keys (first best models) for producing a child\n",
    "    parent_key1=list(sorted_fitness_dict.keys())[0]\n",
    "    parent_key2=list(sorted_fitness_dict.keys())[1]\n",
    "    \n",
    "    #print (parent_key1)\n",
    "    #print (type(parent_key1))\n",
    "    \n",
    "    #print (sorted_fitness_dict[parent_key1][1])\n",
    "    \n",
    "    #generating children from parent 1 and parent 2\n",
    "    unmatched_list=[]\n",
    "    list_parent_1=sorted_fitness_dict[parent_key1][1]\n",
    "    list_parent_2=sorted_fitness_dict[parent_key2][1]\n",
    "    \n",
    "    print (list_parent_1)\n",
    "    print (list_parent_2)\n",
    "    \n",
    "    #child1\n",
    "    child_1_list=[]\n",
    "    child_2_list=[]\n",
    "    for i in range(len(list_parent_1)):\n",
    "        \n",
    "        if (list_parent_1[i]!=list_parent_2[i]):\n",
    "            #unmatched_list.append(i)\n",
    "            param_name=list(param.keys())[i]    #gets the name of the key in the param_dict where the index does not match, eg \"n_neurons\"\n",
    "            par_list=param[param_name]   #par_list contains the values in that name\n",
    "            ind=np.random.randint(0,len(par_list))   # generates random index number from that parameter name\n",
    "            child_1_list.append(par_list[ind])   \n",
    "            child_2_list.append(par_list[ind]) \n",
    "        else:\n",
    "            child_1_list.append(list_parent_1[i])\n",
    "            child_2_list.append(list_parent_1[i])\n",
    "            \n",
    "    print(child_1_list)\n",
    "    #to speed up the process, if the child_1_list has already been computed, just use that value from the sorted_dict_list\n",
    "    for k,v in sorted_fitness_dict.items():\n",
    "        if (v[1]==child_1_list):\n",
    "            child_1_cost=v[0]\n",
    "        else:\n",
    "            child_1_cost=getCost(X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1,child_2_list)\n",
    "            \n",
    "        if (v[1]==child_2_list):\n",
    "            child_2_cost=v[0]\n",
    "        else:\n",
    "            child_2_cost=getCost(X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1,child_2_list)\n",
    "    #child_2_cost=getCost(X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1,child_2_list)\n",
    "    \n",
    "    #adding the new two children by replacing them with the worst ones\n",
    "    \n",
    "    sorted_fitness_dict[key1]=(child_1_cost,child_1_list)\n",
    "    sorted_fitness_dict[key2]=(child_2_cost,child_2_list)\n",
    "    \n",
    "    #typecasting the below statement by dict automatiicaly rearranges the values in ascending order based on keys\n",
    "    sorted_fitness_list = sorted(sorted_fitness_dict.items(),  key=lambda x:x[1],reverse=True)  #returns a list\n",
    "    \n",
    "    for i in sorted_fitness_list:\n",
    "        key=sorted_fitness_list[i][0]\n",
    "        value=sorted_fitness_list[i][1]\n",
    "        sorted_fitness_dict[key]=value\n",
    "    \n",
    "    return sorted_fitness_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateChildren(sorted_fitness_dict,X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.96516832068495817, [15, 10, 0.01]),\n",
       " 1: (0.97139521307647403, [15, 10, 0.1]),\n",
       " 2: (0.96166569371473054, [15, 10, 0.1]),\n",
       " 3: (0.96730881494454179, [20, 10, 0.1]),\n",
       " 4: (0.96302782642537454, [15, 10, 0.1])}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_fitness_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.341816\tBest loss: 0.341816\tAccuracy: 91.01%\n",
      "1\tValidation loss: 0.307190\tBest loss: 0.307190\tAccuracy: 91.28%\n",
      "2\tValidation loss: 0.398243\tBest loss: 0.307190\tAccuracy: 89.44%\n",
      "3\tValidation loss: 0.593868\tBest loss: 0.307190\tAccuracy: 78.26%\n",
      "4\tValidation loss: 0.684187\tBest loss: 0.307190\tAccuracy: 71.15%\n",
      "5\tValidation loss: 0.396820\tBest loss: 0.307190\tAccuracy: 89.37%\n",
      "6\tValidation loss: 0.543564\tBest loss: 0.307190\tAccuracy: 81.20%\n",
      "7\tValidation loss: 0.332144\tBest loss: 0.307190\tAccuracy: 91.52%\n",
      "8\tValidation loss: 0.338050\tBest loss: 0.307190\tAccuracy: 90.77%\n",
      "9\tValidation loss: 0.281040\tBest loss: 0.281040\tAccuracy: 92.34%\n",
      "10\tValidation loss: 0.261848\tBest loss: 0.261848\tAccuracy: 93.35%\n",
      "11\tValidation loss: 0.482828\tBest loss: 0.261848\tAccuracy: 76.70%\n",
      "12\tValidation loss: 0.484601\tBest loss: 0.261848\tAccuracy: 78.23%\n",
      "13\tValidation loss: 0.195486\tBest loss: 0.195486\tAccuracy: 95.15%\n",
      "14\tValidation loss: 0.207603\tBest loss: 0.195486\tAccuracy: 94.76%\n",
      "15\tValidation loss: 0.326859\tBest loss: 0.195486\tAccuracy: 90.42%\n",
      "16\tValidation loss: 0.550053\tBest loss: 0.195486\tAccuracy: 87.76%\n",
      "17\tValidation loss: 0.384603\tBest loss: 0.195486\tAccuracy: 89.80%\n",
      "18\tValidation loss: 0.641617\tBest loss: 0.195486\tAccuracy: 74.43%\n",
      "19\tValidation loss: 0.643914\tBest loss: 0.195486\tAccuracy: 71.93%\n",
      "20\tValidation loss: 0.564388\tBest loss: 0.195486\tAccuracy: 75.45%\n",
      "21\tValidation loss: 0.414717\tBest loss: 0.195486\tAccuracy: 86.63%\n",
      "22\tValidation loss: 0.337832\tBest loss: 0.195486\tAccuracy: 90.23%\n",
      "23\tValidation loss: 0.231739\tBest loss: 0.195486\tAccuracy: 93.94%\n",
      "24\tValidation loss: 0.222204\tBest loss: 0.195486\tAccuracy: 94.37%\n",
      "25\tValidation loss: 0.212984\tBest loss: 0.195486\tAccuracy: 95.19%\n",
      "26\tValidation loss: 0.216009\tBest loss: 0.195486\tAccuracy: 95.27%\n",
      "27\tValidation loss: 0.211321\tBest loss: 0.195486\tAccuracy: 95.19%\n",
      "28\tValidation loss: 0.391445\tBest loss: 0.195486\tAccuracy: 80.22%\n",
      "29\tValidation loss: 0.304695\tBest loss: 0.195486\tAccuracy: 91.16%\n",
      "30\tValidation loss: 0.311594\tBest loss: 0.195486\tAccuracy: 90.42%\n",
      "31\tValidation loss: 0.229520\tBest loss: 0.195486\tAccuracy: 94.29%\n",
      "32\tValidation loss: 0.209314\tBest loss: 0.195486\tAccuracy: 94.96%\n",
      "33\tValidation loss: 0.276910\tBest loss: 0.195486\tAccuracy: 93.12%\n",
      "34\tValidation loss: 0.565778\tBest loss: 0.195486\tAccuracy: 81.35%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.300153\tBest loss: 0.300153\tAccuracy: 93.20%\n",
      "1\tValidation loss: 0.398980\tBest loss: 0.300153\tAccuracy: 91.67%\n",
      "2\tValidation loss: 0.414788\tBest loss: 0.300153\tAccuracy: 89.52%\n",
      "3\tValidation loss: 0.273818\tBest loss: 0.273818\tAccuracy: 92.77%\n",
      "4\tValidation loss: 0.229183\tBest loss: 0.229183\tAccuracy: 94.25%\n",
      "5\tValidation loss: 0.293192\tBest loss: 0.229183\tAccuracy: 92.38%\n",
      "6\tValidation loss: 0.457821\tBest loss: 0.229183\tAccuracy: 85.93%\n",
      "7\tValidation loss: 0.472951\tBest loss: 0.229183\tAccuracy: 86.43%\n",
      "8\tValidation loss: 0.310489\tBest loss: 0.229183\tAccuracy: 92.89%\n",
      "9\tValidation loss: 0.264723\tBest loss: 0.229183\tAccuracy: 94.33%\n",
      "10\tValidation loss: 0.232236\tBest loss: 0.229183\tAccuracy: 93.67%\n",
      "11\tValidation loss: 0.779516\tBest loss: 0.229183\tAccuracy: 66.65%\n",
      "12\tValidation loss: 0.378685\tBest loss: 0.229183\tAccuracy: 89.01%\n",
      "13\tValidation loss: 0.368607\tBest loss: 0.229183\tAccuracy: 90.70%\n",
      "14\tValidation loss: 1.165038\tBest loss: 0.229183\tAccuracy: 43.20%\n",
      "15\tValidation loss: 0.867567\tBest loss: 0.229183\tAccuracy: 56.06%\n",
      "16\tValidation loss: 1.612251\tBest loss: 0.229183\tAccuracy: 40.15%\n",
      "17\tValidation loss: 1.150348\tBest loss: 0.229183\tAccuracy: 39.60%\n",
      "18\tValidation loss: 1.154551\tBest loss: 0.229183\tAccuracy: 39.60%\n",
      "19\tValidation loss: 1.150949\tBest loss: 0.229183\tAccuracy: 39.87%\n",
      "20\tValidation loss: 1.147960\tBest loss: 0.229183\tAccuracy: 39.87%\n",
      "21\tValidation loss: 1.152037\tBest loss: 0.229183\tAccuracy: 40.15%\n",
      "22\tValidation loss: 1.153344\tBest loss: 0.229183\tAccuracy: 41.75%\n",
      "23\tValidation loss: 1.163513\tBest loss: 0.229183\tAccuracy: 39.87%\n",
      "24\tValidation loss: 1.147767\tBest loss: 0.229183\tAccuracy: 41.75%\n",
      "25\tValidation loss: 1.208353\tBest loss: 0.229183\tAccuracy: 40.46%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.462437\tBest loss: 0.462437\tAccuracy: 76.54%\n",
      "1\tValidation loss: 0.454093\tBest loss: 0.454093\tAccuracy: 77.68%\n",
      "2\tValidation loss: 0.491192\tBest loss: 0.454093\tAccuracy: 85.26%\n",
      "3\tValidation loss: 0.625557\tBest loss: 0.454093\tAccuracy: 74.98%\n",
      "4\tValidation loss: 0.199139\tBest loss: 0.199139\tAccuracy: 95.27%\n",
      "5\tValidation loss: 0.180429\tBest loss: 0.180429\tAccuracy: 95.97%\n",
      "6\tValidation loss: 0.266746\tBest loss: 0.180429\tAccuracy: 93.94%\n",
      "7\tValidation loss: 0.291929\tBest loss: 0.180429\tAccuracy: 91.95%\n",
      "8\tValidation loss: 0.306201\tBest loss: 0.180429\tAccuracy: 91.91%\n",
      "9\tValidation loss: 0.346376\tBest loss: 0.180429\tAccuracy: 88.82%\n",
      "10\tValidation loss: 0.355556\tBest loss: 0.180429\tAccuracy: 89.33%\n",
      "11\tValidation loss: 0.301914\tBest loss: 0.180429\tAccuracy: 91.79%\n",
      "12\tValidation loss: 0.244036\tBest loss: 0.180429\tAccuracy: 93.39%\n",
      "13\tValidation loss: 0.368588\tBest loss: 0.180429\tAccuracy: 86.12%\n",
      "14\tValidation loss: 0.623625\tBest loss: 0.180429\tAccuracy: 72.13%\n",
      "15\tValidation loss: 1.159778\tBest loss: 0.180429\tAccuracy: 40.54%\n",
      "16\tValidation loss: 1.141263\tBest loss: 0.180429\tAccuracy: 40.70%\n",
      "17\tValidation loss: 1.615226\tBest loss: 0.180429\tAccuracy: 18.92%\n",
      "18\tValidation loss: 1.613437\tBest loss: 0.180429\tAccuracy: 20.91%\n",
      "19\tValidation loss: 1.611069\tBest loss: 0.180429\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.607477\tBest loss: 0.180429\tAccuracy: 19.23%\n",
      "21\tValidation loss: 1.611484\tBest loss: 0.180429\tAccuracy: 19.08%\n",
      "22\tValidation loss: 1.612188\tBest loss: 0.180429\tAccuracy: 19.19%\n",
      "23\tValidation loss: 1.634311\tBest loss: 0.180429\tAccuracy: 19.27%\n",
      "24\tValidation loss: 1.625313\tBest loss: 0.180429\tAccuracy: 19.08%\n",
      "25\tValidation loss: 1.617299\tBest loss: 0.180429\tAccuracy: 22.09%\n",
      "26\tValidation loss: 1.616196\tBest loss: 0.180429\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.421518\tBest loss: 0.421518\tAccuracy: 87.88%\n",
      "1\tValidation loss: 0.610792\tBest loss: 0.421518\tAccuracy: 75.37%\n",
      "2\tValidation loss: 0.297160\tBest loss: 0.297160\tAccuracy: 93.47%\n",
      "3\tValidation loss: 0.784594\tBest loss: 0.297160\tAccuracy: 57.00%\n",
      "4\tValidation loss: 0.853087\tBest loss: 0.297160\tAccuracy: 54.03%\n",
      "5\tValidation loss: 1.107490\tBest loss: 0.297160\tAccuracy: 54.22%\n",
      "6\tValidation loss: 0.297896\tBest loss: 0.297160\tAccuracy: 92.10%\n",
      "7\tValidation loss: 0.372215\tBest loss: 0.297160\tAccuracy: 91.99%\n",
      "8\tValidation loss: 0.748846\tBest loss: 0.297160\tAccuracy: 69.90%\n",
      "9\tValidation loss: 0.363154\tBest loss: 0.297160\tAccuracy: 90.27%\n",
      "10\tValidation loss: 0.388012\tBest loss: 0.297160\tAccuracy: 87.92%\n",
      "11\tValidation loss: 0.389155\tBest loss: 0.297160\tAccuracy: 89.64%\n",
      "12\tValidation loss: 0.437152\tBest loss: 0.297160\tAccuracy: 91.24%\n",
      "13\tValidation loss: 0.453012\tBest loss: 0.297160\tAccuracy: 93.94%\n",
      "14\tValidation loss: 0.444576\tBest loss: 0.297160\tAccuracy: 89.01%\n",
      "15\tValidation loss: 0.291333\tBest loss: 0.291333\tAccuracy: 93.51%\n",
      "16\tValidation loss: 0.335084\tBest loss: 0.291333\tAccuracy: 92.69%\n",
      "17\tValidation loss: 0.427098\tBest loss: 0.291333\tAccuracy: 93.63%\n",
      "18\tValidation loss: 0.276326\tBest loss: 0.276326\tAccuracy: 94.96%\n",
      "19\tValidation loss: 0.207363\tBest loss: 0.207363\tAccuracy: 95.78%\n",
      "20\tValidation loss: 0.237950\tBest loss: 0.207363\tAccuracy: 95.19%\n",
      "21\tValidation loss: 0.268758\tBest loss: 0.207363\tAccuracy: 95.11%\n",
      "22\tValidation loss: 0.205862\tBest loss: 0.205862\tAccuracy: 96.36%\n",
      "23\tValidation loss: 0.439841\tBest loss: 0.205862\tAccuracy: 77.52%\n",
      "24\tValidation loss: 0.927191\tBest loss: 0.205862\tAccuracy: 58.44%\n",
      "25\tValidation loss: 0.623762\tBest loss: 0.205862\tAccuracy: 78.58%\n",
      "26\tValidation loss: 0.456700\tBest loss: 0.205862\tAccuracy: 79.09%\n",
      "27\tValidation loss: 0.427737\tBest loss: 0.205862\tAccuracy: 78.07%\n",
      "28\tValidation loss: 0.403875\tBest loss: 0.205862\tAccuracy: 79.24%\n",
      "29\tValidation loss: 0.436434\tBest loss: 0.205862\tAccuracy: 77.83%\n",
      "30\tValidation loss: 0.400889\tBest loss: 0.205862\tAccuracy: 79.01%\n",
      "31\tValidation loss: 0.477120\tBest loss: 0.205862\tAccuracy: 77.64%\n",
      "32\tValidation loss: 0.462514\tBest loss: 0.205862\tAccuracy: 79.16%\n",
      "33\tValidation loss: 0.410496\tBest loss: 0.205862\tAccuracy: 79.01%\n",
      "34\tValidation loss: 0.469205\tBest loss: 0.205862\tAccuracy: 76.90%\n",
      "35\tValidation loss: 0.491593\tBest loss: 0.205862\tAccuracy: 77.01%\n",
      "36\tValidation loss: 0.433251\tBest loss: 0.205862\tAccuracy: 78.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\tValidation loss: 0.402780\tBest loss: 0.205862\tAccuracy: 79.12%\n",
      "38\tValidation loss: 0.480582\tBest loss: 0.205862\tAccuracy: 78.77%\n",
      "39\tValidation loss: 0.436078\tBest loss: 0.205862\tAccuracy: 83.31%\n",
      "40\tValidation loss: 3.275888\tBest loss: 0.205862\tAccuracy: 33.97%\n",
      "41\tValidation loss: 0.306263\tBest loss: 0.205862\tAccuracy: 91.59%\n",
      "42\tValidation loss: 0.199373\tBest loss: 0.199373\tAccuracy: 95.31%\n",
      "43\tValidation loss: 0.190517\tBest loss: 0.190517\tAccuracy: 95.66%\n",
      "44\tValidation loss: 1.289186\tBest loss: 0.190517\tAccuracy: 37.18%\n",
      "45\tValidation loss: 1.331232\tBest loss: 0.190517\tAccuracy: 32.72%\n",
      "46\tValidation loss: 1.583658\tBest loss: 0.190517\tAccuracy: 19.27%\n",
      "47\tValidation loss: 1.581042\tBest loss: 0.190517\tAccuracy: 20.60%\n",
      "48\tValidation loss: 1.610905\tBest loss: 0.190517\tAccuracy: 23.89%\n",
      "49\tValidation loss: 1.583603\tBest loss: 0.190517\tAccuracy: 20.60%\n",
      "50\tValidation loss: 1.596970\tBest loss: 0.190517\tAccuracy: 23.89%\n",
      "51\tValidation loss: 1.584650\tBest loss: 0.190517\tAccuracy: 20.95%\n",
      "52\tValidation loss: 1.581919\tBest loss: 0.190517\tAccuracy: 23.89%\n",
      "53\tValidation loss: 1.601349\tBest loss: 0.190517\tAccuracy: 23.89%\n",
      "54\tValidation loss: 1.626931\tBest loss: 0.190517\tAccuracy: 20.91%\n",
      "55\tValidation loss: 1.616043\tBest loss: 0.190517\tAccuracy: 22.01%\n",
      "56\tValidation loss: 1.613410\tBest loss: 0.190517\tAccuracy: 18.73%\n",
      "57\tValidation loss: 1.608899\tBest loss: 0.190517\tAccuracy: 22.01%\n",
      "58\tValidation loss: 1.619153\tBest loss: 0.190517\tAccuracy: 22.01%\n",
      "59\tValidation loss: 1.612401\tBest loss: 0.190517\tAccuracy: 22.01%\n",
      "60\tValidation loss: 1.618158\tBest loss: 0.190517\tAccuracy: 18.73%\n",
      "61\tValidation loss: 1.621431\tBest loss: 0.190517\tAccuracy: 22.01%\n",
      "62\tValidation loss: 1.622113\tBest loss: 0.190517\tAccuracy: 22.01%\n",
      "63\tValidation loss: 1.627619\tBest loss: 0.190517\tAccuracy: 22.01%\n",
      "64\tValidation loss: 1.613172\tBest loss: 0.190517\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.191185\tBest loss: 0.191185\tAccuracy: 94.80%\n",
      "1\tValidation loss: 0.335217\tBest loss: 0.191185\tAccuracy: 90.54%\n",
      "2\tValidation loss: 0.588310\tBest loss: 0.191185\tAccuracy: 86.51%\n",
      "3\tValidation loss: 0.192338\tBest loss: 0.191185\tAccuracy: 95.35%\n",
      "4\tValidation loss: 0.258908\tBest loss: 0.191185\tAccuracy: 92.61%\n",
      "5\tValidation loss: 0.264476\tBest loss: 0.191185\tAccuracy: 91.44%\n",
      "6\tValidation loss: 0.424997\tBest loss: 0.191185\tAccuracy: 87.29%\n",
      "7\tValidation loss: 0.358741\tBest loss: 0.191185\tAccuracy: 90.81%\n",
      "8\tValidation loss: 0.332927\tBest loss: 0.191185\tAccuracy: 93.08%\n",
      "9\tValidation loss: 0.449903\tBest loss: 0.191185\tAccuracy: 88.51%\n",
      "10\tValidation loss: 0.444795\tBest loss: 0.191185\tAccuracy: 83.58%\n",
      "11\tValidation loss: 0.265855\tBest loss: 0.191185\tAccuracy: 93.55%\n",
      "12\tValidation loss: 0.393642\tBest loss: 0.191185\tAccuracy: 89.17%\n",
      "13\tValidation loss: 0.287378\tBest loss: 0.191185\tAccuracy: 92.89%\n",
      "14\tValidation loss: 0.312124\tBest loss: 0.191185\tAccuracy: 91.40%\n",
      "15\tValidation loss: 0.760767\tBest loss: 0.191185\tAccuracy: 67.83%\n",
      "16\tValidation loss: 0.721929\tBest loss: 0.191185\tAccuracy: 68.80%\n",
      "17\tValidation loss: 0.387427\tBest loss: 0.191185\tAccuracy: 88.43%\n",
      "18\tValidation loss: 0.672984\tBest loss: 0.191185\tAccuracy: 71.50%\n",
      "19\tValidation loss: 1.003836\tBest loss: 0.191185\tAccuracy: 53.91%\n",
      "20\tValidation loss: 0.307536\tBest loss: 0.191185\tAccuracy: 91.63%\n",
      "21\tValidation loss: 0.416035\tBest loss: 0.191185\tAccuracy: 86.90%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.553738\tBest loss: 0.553738\tAccuracy: 81.24%\n",
      "1\tValidation loss: 0.352502\tBest loss: 0.352502\tAccuracy: 90.66%\n",
      "2\tValidation loss: 1.211940\tBest loss: 0.352502\tAccuracy: 39.99%\n",
      "3\tValidation loss: 1.075634\tBest loss: 0.352502\tAccuracy: 49.80%\n",
      "4\tValidation loss: 0.395172\tBest loss: 0.352502\tAccuracy: 88.23%\n",
      "5\tValidation loss: 0.767889\tBest loss: 0.352502\tAccuracy: 58.56%\n",
      "6\tValidation loss: 0.844816\tBest loss: 0.352502\tAccuracy: 58.56%\n",
      "7\tValidation loss: 0.812938\tBest loss: 0.352502\tAccuracy: 57.04%\n",
      "8\tValidation loss: 0.768276\tBest loss: 0.352502\tAccuracy: 59.85%\n",
      "9\tValidation loss: 0.853575\tBest loss: 0.352502\tAccuracy: 55.98%\n",
      "10\tValidation loss: 1.126976\tBest loss: 0.352502\tAccuracy: 40.77%\n",
      "11\tValidation loss: 1.143723\tBest loss: 0.352502\tAccuracy: 40.03%\n",
      "12\tValidation loss: 0.466120\tBest loss: 0.352502\tAccuracy: 78.73%\n",
      "13\tValidation loss: 0.381662\tBest loss: 0.352502\tAccuracy: 87.49%\n",
      "14\tValidation loss: 0.435752\tBest loss: 0.352502\tAccuracy: 86.04%\n",
      "15\tValidation loss: 0.321505\tBest loss: 0.321505\tAccuracy: 90.77%\n",
      "16\tValidation loss: 0.435444\tBest loss: 0.321505\tAccuracy: 85.46%\n",
      "17\tValidation loss: 0.303105\tBest loss: 0.303105\tAccuracy: 90.50%\n",
      "18\tValidation loss: 0.302900\tBest loss: 0.302900\tAccuracy: 91.09%\n",
      "19\tValidation loss: 0.254767\tBest loss: 0.254767\tAccuracy: 93.47%\n",
      "20\tValidation loss: 0.282084\tBest loss: 0.254767\tAccuracy: 92.61%\n",
      "21\tValidation loss: 0.274927\tBest loss: 0.254767\tAccuracy: 93.12%\n",
      "22\tValidation loss: 0.310899\tBest loss: 0.254767\tAccuracy: 91.32%\n",
      "23\tValidation loss: 0.273823\tBest loss: 0.254767\tAccuracy: 92.77%\n",
      "24\tValidation loss: 0.283140\tBest loss: 0.254767\tAccuracy: 92.73%\n",
      "25\tValidation loss: 0.259941\tBest loss: 0.254767\tAccuracy: 94.45%\n",
      "26\tValidation loss: 0.236195\tBest loss: 0.236195\tAccuracy: 94.80%\n",
      "27\tValidation loss: 0.259648\tBest loss: 0.236195\tAccuracy: 94.06%\n",
      "28\tValidation loss: 0.332176\tBest loss: 0.236195\tAccuracy: 86.40%\n",
      "29\tValidation loss: 0.241511\tBest loss: 0.236195\tAccuracy: 94.10%\n",
      "30\tValidation loss: 0.433747\tBest loss: 0.236195\tAccuracy: 88.27%\n",
      "31\tValidation loss: 0.250272\tBest loss: 0.236195\tAccuracy: 93.20%\n",
      "32\tValidation loss: 0.258927\tBest loss: 0.236195\tAccuracy: 93.67%\n",
      "33\tValidation loss: 0.415565\tBest loss: 0.236195\tAccuracy: 86.00%\n",
      "34\tValidation loss: 0.514768\tBest loss: 0.236195\tAccuracy: 81.70%\n",
      "35\tValidation loss: 0.494530\tBest loss: 0.236195\tAccuracy: 80.81%\n",
      "36\tValidation loss: 0.305537\tBest loss: 0.236195\tAccuracy: 91.83%\n",
      "37\tValidation loss: 0.520164\tBest loss: 0.236195\tAccuracy: 73.18%\n",
      "38\tValidation loss: 0.543418\tBest loss: 0.236195\tAccuracy: 72.83%\n",
      "39\tValidation loss: 0.857678\tBest loss: 0.236195\tAccuracy: 59.27%\n",
      "40\tValidation loss: 0.546622\tBest loss: 0.236195\tAccuracy: 74.63%\n",
      "41\tValidation loss: 0.494564\tBest loss: 0.236195\tAccuracy: 78.42%\n",
      "42\tValidation loss: 0.494671\tBest loss: 0.236195\tAccuracy: 77.68%\n",
      "43\tValidation loss: 0.484310\tBest loss: 0.236195\tAccuracy: 82.53%\n",
      "44\tValidation loss: 0.492009\tBest loss: 0.236195\tAccuracy: 79.98%\n",
      "45\tValidation loss: 0.311064\tBest loss: 0.236195\tAccuracy: 93.55%\n",
      "46\tValidation loss: 0.478616\tBest loss: 0.236195\tAccuracy: 75.72%\n",
      "47\tValidation loss: 0.485176\tBest loss: 0.236195\tAccuracy: 74.75%\n",
      "Early stopping!\n",
      "generation no: 0\n",
      "[15, 10, 0.01]\n",
      "[20, 10, 0.001]\n",
      "[5, 10, 0.0001]\n",
      "0\tValidation loss: 0.092716\tBest loss: 0.092716\tAccuracy: 97.50%\n",
      "1\tValidation loss: 0.078001\tBest loss: 0.078001\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.089370\tBest loss: 0.078001\tAccuracy: 97.89%\n",
      "3\tValidation loss: 0.087456\tBest loss: 0.078001\tAccuracy: 97.42%\n",
      "4\tValidation loss: 0.088802\tBest loss: 0.078001\tAccuracy: 97.77%\n",
      "5\tValidation loss: 0.097042\tBest loss: 0.078001\tAccuracy: 97.42%\n",
      "6\tValidation loss: 0.098174\tBest loss: 0.078001\tAccuracy: 97.73%\n",
      "7\tValidation loss: 0.083479\tBest loss: 0.078001\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.087425\tBest loss: 0.078001\tAccuracy: 97.81%\n",
      "9\tValidation loss: 0.093445\tBest loss: 0.078001\tAccuracy: 97.62%\n",
      "10\tValidation loss: 0.089720\tBest loss: 0.078001\tAccuracy: 97.93%\n",
      "11\tValidation loss: 0.079947\tBest loss: 0.078001\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.091756\tBest loss: 0.078001\tAccuracy: 98.05%\n",
      "13\tValidation loss: 0.081474\tBest loss: 0.078001\tAccuracy: 97.85%\n",
      "14\tValidation loss: 0.085294\tBest loss: 0.078001\tAccuracy: 97.69%\n",
      "15\tValidation loss: 0.104763\tBest loss: 0.078001\tAccuracy: 97.65%\n",
      "16\tValidation loss: 0.081497\tBest loss: 0.078001\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.074404\tBest loss: 0.074404\tAccuracy: 97.85%\n",
      "18\tValidation loss: 0.088492\tBest loss: 0.074404\tAccuracy: 98.08%\n",
      "19\tValidation loss: 0.094653\tBest loss: 0.074404\tAccuracy: 97.77%\n",
      "20\tValidation loss: 0.081001\tBest loss: 0.074404\tAccuracy: 98.20%\n",
      "21\tValidation loss: 0.089705\tBest loss: 0.074404\tAccuracy: 97.81%\n",
      "22\tValidation loss: 0.083884\tBest loss: 0.074404\tAccuracy: 97.69%\n",
      "23\tValidation loss: 0.086306\tBest loss: 0.074404\tAccuracy: 97.58%\n",
      "24\tValidation loss: 0.126735\tBest loss: 0.074404\tAccuracy: 97.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\tValidation loss: 0.092324\tBest loss: 0.074404\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.083122\tBest loss: 0.074404\tAccuracy: 97.77%\n",
      "27\tValidation loss: 0.072871\tBest loss: 0.072871\tAccuracy: 98.32%\n",
      "28\tValidation loss: 0.091993\tBest loss: 0.072871\tAccuracy: 98.01%\n",
      "29\tValidation loss: 0.104250\tBest loss: 0.072871\tAccuracy: 98.32%\n",
      "30\tValidation loss: 0.092477\tBest loss: 0.072871\tAccuracy: 98.05%\n",
      "31\tValidation loss: 0.072046\tBest loss: 0.072046\tAccuracy: 98.01%\n",
      "32\tValidation loss: 0.091952\tBest loss: 0.072046\tAccuracy: 98.01%\n",
      "33\tValidation loss: 0.078987\tBest loss: 0.072046\tAccuracy: 98.28%\n",
      "34\tValidation loss: 0.089436\tBest loss: 0.072046\tAccuracy: 98.01%\n",
      "35\tValidation loss: 0.137224\tBest loss: 0.072046\tAccuracy: 97.81%\n",
      "36\tValidation loss: 0.098751\tBest loss: 0.072046\tAccuracy: 97.73%\n",
      "37\tValidation loss: 0.103396\tBest loss: 0.072046\tAccuracy: 97.97%\n",
      "38\tValidation loss: 0.075644\tBest loss: 0.072046\tAccuracy: 98.51%\n",
      "39\tValidation loss: 0.099174\tBest loss: 0.072046\tAccuracy: 98.28%\n",
      "40\tValidation loss: 0.098318\tBest loss: 0.072046\tAccuracy: 98.24%\n",
      "41\tValidation loss: 0.093118\tBest loss: 0.072046\tAccuracy: 98.01%\n",
      "42\tValidation loss: 0.115854\tBest loss: 0.072046\tAccuracy: 97.77%\n",
      "43\tValidation loss: 0.080129\tBest loss: 0.072046\tAccuracy: 98.20%\n",
      "44\tValidation loss: 0.109926\tBest loss: 0.072046\tAccuracy: 98.05%\n",
      "45\tValidation loss: 0.097789\tBest loss: 0.072046\tAccuracy: 98.12%\n",
      "46\tValidation loss: 0.128298\tBest loss: 0.072046\tAccuracy: 98.01%\n",
      "47\tValidation loss: 0.121598\tBest loss: 0.072046\tAccuracy: 97.89%\n",
      "48\tValidation loss: 0.110738\tBest loss: 0.072046\tAccuracy: 98.08%\n",
      "49\tValidation loss: 0.126532\tBest loss: 0.072046\tAccuracy: 97.62%\n",
      "50\tValidation loss: 0.107873\tBest loss: 0.072046\tAccuracy: 97.89%\n",
      "51\tValidation loss: 0.119853\tBest loss: 0.072046\tAccuracy: 98.05%\n",
      "52\tValidation loss: 0.112007\tBest loss: 0.072046\tAccuracy: 98.12%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.105564\tBest loss: 0.105564\tAccuracy: 97.19%\n",
      "1\tValidation loss: 0.087016\tBest loss: 0.087016\tAccuracy: 97.30%\n",
      "2\tValidation loss: 0.078905\tBest loss: 0.078905\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.074795\tBest loss: 0.074795\tAccuracy: 98.12%\n",
      "4\tValidation loss: 0.072288\tBest loss: 0.072288\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.080888\tBest loss: 0.072288\tAccuracy: 97.69%\n",
      "6\tValidation loss: 0.063592\tBest loss: 0.063592\tAccuracy: 98.44%\n",
      "7\tValidation loss: 0.072599\tBest loss: 0.063592\tAccuracy: 98.32%\n",
      "8\tValidation loss: 0.083505\tBest loss: 0.063592\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.123363\tBest loss: 0.063592\tAccuracy: 97.54%\n",
      "10\tValidation loss: 0.077949\tBest loss: 0.063592\tAccuracy: 98.36%\n",
      "11\tValidation loss: 0.088389\tBest loss: 0.063592\tAccuracy: 98.32%\n",
      "12\tValidation loss: 0.064618\tBest loss: 0.063592\tAccuracy: 98.63%\n",
      "13\tValidation loss: 0.077920\tBest loss: 0.063592\tAccuracy: 98.63%\n",
      "14\tValidation loss: 0.095438\tBest loss: 0.063592\tAccuracy: 98.28%\n",
      "15\tValidation loss: 0.064038\tBest loss: 0.063592\tAccuracy: 98.55%\n",
      "16\tValidation loss: 0.066041\tBest loss: 0.063592\tAccuracy: 98.55%\n",
      "17\tValidation loss: 0.072599\tBest loss: 0.063592\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.082310\tBest loss: 0.063592\tAccuracy: 98.51%\n",
      "19\tValidation loss: 0.070338\tBest loss: 0.063592\tAccuracy: 98.40%\n",
      "20\tValidation loss: 0.096726\tBest loss: 0.063592\tAccuracy: 98.05%\n",
      "21\tValidation loss: 0.068007\tBest loss: 0.063592\tAccuracy: 98.51%\n",
      "22\tValidation loss: 0.115050\tBest loss: 0.063592\tAccuracy: 97.77%\n",
      "23\tValidation loss: 0.108201\tBest loss: 0.063592\tAccuracy: 98.28%\n",
      "24\tValidation loss: 0.077796\tBest loss: 0.063592\tAccuracy: 98.32%\n",
      "25\tValidation loss: 0.087486\tBest loss: 0.063592\tAccuracy: 98.16%\n",
      "26\tValidation loss: 0.070159\tBest loss: 0.063592\tAccuracy: 98.44%\n",
      "27\tValidation loss: 0.082468\tBest loss: 0.063592\tAccuracy: 98.05%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.095524\tBest loss: 0.095524\tAccuracy: 97.69%\n",
      "1\tValidation loss: 0.082855\tBest loss: 0.082855\tAccuracy: 97.62%\n",
      "2\tValidation loss: 0.084241\tBest loss: 0.082855\tAccuracy: 97.81%\n",
      "3\tValidation loss: 0.069571\tBest loss: 0.069571\tAccuracy: 98.16%\n",
      "4\tValidation loss: 0.121091\tBest loss: 0.069571\tAccuracy: 97.46%\n",
      "5\tValidation loss: 0.085777\tBest loss: 0.069571\tAccuracy: 97.81%\n",
      "6\tValidation loss: 0.073216\tBest loss: 0.069571\tAccuracy: 97.85%\n",
      "7\tValidation loss: 0.097357\tBest loss: 0.069571\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.084250\tBest loss: 0.069571\tAccuracy: 98.12%\n",
      "9\tValidation loss: 0.099849\tBest loss: 0.069571\tAccuracy: 97.77%\n",
      "10\tValidation loss: 0.088563\tBest loss: 0.069571\tAccuracy: 97.58%\n",
      "11\tValidation loss: 0.068460\tBest loss: 0.068460\tAccuracy: 98.63%\n",
      "12\tValidation loss: 0.097607\tBest loss: 0.068460\tAccuracy: 98.01%\n",
      "13\tValidation loss: 0.095300\tBest loss: 0.068460\tAccuracy: 97.77%\n",
      "14\tValidation loss: 0.093670\tBest loss: 0.068460\tAccuracy: 98.16%\n",
      "15\tValidation loss: 0.101187\tBest loss: 0.068460\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.103530\tBest loss: 0.068460\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.090644\tBest loss: 0.068460\tAccuracy: 98.20%\n",
      "18\tValidation loss: 0.101054\tBest loss: 0.068460\tAccuracy: 98.08%\n",
      "19\tValidation loss: 0.104274\tBest loss: 0.068460\tAccuracy: 98.40%\n",
      "20\tValidation loss: 0.097232\tBest loss: 0.068460\tAccuracy: 98.05%\n",
      "21\tValidation loss: 0.139713\tBest loss: 0.068460\tAccuracy: 97.73%\n",
      "22\tValidation loss: 0.098541\tBest loss: 0.068460\tAccuracy: 98.12%\n",
      "23\tValidation loss: 0.100278\tBest loss: 0.068460\tAccuracy: 98.24%\n",
      "24\tValidation loss: 0.107474\tBest loss: 0.068460\tAccuracy: 98.24%\n",
      "25\tValidation loss: 0.119215\tBest loss: 0.068460\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.079345\tBest loss: 0.068460\tAccuracy: 98.24%\n",
      "27\tValidation loss: 0.092468\tBest loss: 0.068460\tAccuracy: 98.01%\n",
      "28\tValidation loss: 0.114209\tBest loss: 0.068460\tAccuracy: 97.89%\n",
      "29\tValidation loss: 0.101557\tBest loss: 0.068460\tAccuracy: 98.44%\n",
      "30\tValidation loss: 0.106928\tBest loss: 0.068460\tAccuracy: 98.24%\n",
      "31\tValidation loss: 0.123554\tBest loss: 0.068460\tAccuracy: 98.32%\n",
      "32\tValidation loss: 0.154422\tBest loss: 0.068460\tAccuracy: 97.89%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.091657\tBest loss: 0.091657\tAccuracy: 97.69%\n",
      "1\tValidation loss: 0.122792\tBest loss: 0.091657\tAccuracy: 96.72%\n",
      "2\tValidation loss: 0.117848\tBest loss: 0.091657\tAccuracy: 96.68%\n",
      "3\tValidation loss: 0.073836\tBest loss: 0.073836\tAccuracy: 98.16%\n",
      "4\tValidation loss: 0.085772\tBest loss: 0.073836\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.088962\tBest loss: 0.073836\tAccuracy: 97.93%\n",
      "6\tValidation loss: 0.072709\tBest loss: 0.072709\tAccuracy: 98.12%\n",
      "7\tValidation loss: 0.078566\tBest loss: 0.072709\tAccuracy: 98.05%\n",
      "8\tValidation loss: 0.073277\tBest loss: 0.072709\tAccuracy: 98.08%\n",
      "9\tValidation loss: 0.087371\tBest loss: 0.072709\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.085177\tBest loss: 0.072709\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.083125\tBest loss: 0.072709\tAccuracy: 98.01%\n",
      "12\tValidation loss: 0.082615\tBest loss: 0.072709\tAccuracy: 98.16%\n",
      "13\tValidation loss: 0.085692\tBest loss: 0.072709\tAccuracy: 97.65%\n",
      "14\tValidation loss: 0.113953\tBest loss: 0.072709\tAccuracy: 97.50%\n",
      "15\tValidation loss: 0.099141\tBest loss: 0.072709\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.107365\tBest loss: 0.072709\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.102494\tBest loss: 0.072709\tAccuracy: 98.12%\n",
      "18\tValidation loss: 0.141268\tBest loss: 0.072709\tAccuracy: 97.65%\n",
      "19\tValidation loss: 0.088994\tBest loss: 0.072709\tAccuracy: 97.97%\n",
      "20\tValidation loss: 0.106766\tBest loss: 0.072709\tAccuracy: 98.24%\n",
      "21\tValidation loss: 0.086853\tBest loss: 0.072709\tAccuracy: 98.12%\n",
      "22\tValidation loss: 0.080640\tBest loss: 0.072709\tAccuracy: 97.97%\n",
      "23\tValidation loss: 0.078794\tBest loss: 0.072709\tAccuracy: 98.12%\n",
      "24\tValidation loss: 0.087782\tBest loss: 0.072709\tAccuracy: 98.05%\n",
      "25\tValidation loss: 0.112003\tBest loss: 0.072709\tAccuracy: 97.93%\n",
      "26\tValidation loss: 0.084148\tBest loss: 0.072709\tAccuracy: 98.16%\n",
      "27\tValidation loss: 0.112265\tBest loss: 0.072709\tAccuracy: 97.77%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.121800\tBest loss: 0.121800\tAccuracy: 96.25%\n",
      "1\tValidation loss: 0.091344\tBest loss: 0.091344\tAccuracy: 97.26%\n",
      "2\tValidation loss: 0.099879\tBest loss: 0.091344\tAccuracy: 97.38%\n",
      "3\tValidation loss: 0.076108\tBest loss: 0.076108\tAccuracy: 97.62%\n",
      "4\tValidation loss: 0.108998\tBest loss: 0.076108\tAccuracy: 96.99%\n",
      "5\tValidation loss: 0.078335\tBest loss: 0.076108\tAccuracy: 97.65%\n",
      "6\tValidation loss: 0.074560\tBest loss: 0.074560\tAccuracy: 98.01%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\tValidation loss: 0.112907\tBest loss: 0.074560\tAccuracy: 97.73%\n",
      "8\tValidation loss: 0.091345\tBest loss: 0.074560\tAccuracy: 97.46%\n",
      "9\tValidation loss: 0.085484\tBest loss: 0.074560\tAccuracy: 97.65%\n",
      "10\tValidation loss: 0.080211\tBest loss: 0.074560\tAccuracy: 97.97%\n",
      "11\tValidation loss: 0.118857\tBest loss: 0.074560\tAccuracy: 97.30%\n",
      "12\tValidation loss: 0.087438\tBest loss: 0.074560\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.084605\tBest loss: 0.074560\tAccuracy: 97.85%\n",
      "14\tValidation loss: 0.075725\tBest loss: 0.074560\tAccuracy: 97.85%\n",
      "15\tValidation loss: 0.078562\tBest loss: 0.074560\tAccuracy: 97.62%\n",
      "16\tValidation loss: 0.114954\tBest loss: 0.074560\tAccuracy: 97.54%\n",
      "17\tValidation loss: 0.114267\tBest loss: 0.074560\tAccuracy: 98.01%\n",
      "18\tValidation loss: 0.090053\tBest loss: 0.074560\tAccuracy: 97.34%\n",
      "19\tValidation loss: 0.080613\tBest loss: 0.074560\tAccuracy: 98.05%\n",
      "20\tValidation loss: 0.091760\tBest loss: 0.074560\tAccuracy: 97.81%\n",
      "21\tValidation loss: 0.114324\tBest loss: 0.074560\tAccuracy: 97.50%\n",
      "22\tValidation loss: 0.104836\tBest loss: 0.074560\tAccuracy: 97.93%\n",
      "23\tValidation loss: 0.089595\tBest loss: 0.074560\tAccuracy: 97.73%\n",
      "24\tValidation loss: 0.117086\tBest loss: 0.074560\tAccuracy: 97.69%\n",
      "25\tValidation loss: 0.108911\tBest loss: 0.074560\tAccuracy: 98.16%\n",
      "26\tValidation loss: 0.105385\tBest loss: 0.074560\tAccuracy: 97.69%\n",
      "27\tValidation loss: 0.132497\tBest loss: 0.074560\tAccuracy: 97.30%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.096218\tBest loss: 0.096218\tAccuracy: 97.15%\n",
      "1\tValidation loss: 0.087081\tBest loss: 0.087081\tAccuracy: 97.54%\n",
      "2\tValidation loss: 0.100891\tBest loss: 0.087081\tAccuracy: 97.07%\n",
      "3\tValidation loss: 0.117322\tBest loss: 0.087081\tAccuracy: 97.15%\n",
      "4\tValidation loss: 0.103782\tBest loss: 0.087081\tAccuracy: 97.11%\n",
      "5\tValidation loss: 0.089633\tBest loss: 0.087081\tAccuracy: 97.69%\n",
      "6\tValidation loss: 0.077042\tBest loss: 0.077042\tAccuracy: 97.93%\n",
      "7\tValidation loss: 0.116904\tBest loss: 0.077042\tAccuracy: 96.60%\n",
      "8\tValidation loss: 0.091137\tBest loss: 0.077042\tAccuracy: 98.16%\n",
      "9\tValidation loss: 0.083753\tBest loss: 0.077042\tAccuracy: 97.81%\n",
      "10\tValidation loss: 0.077316\tBest loss: 0.077042\tAccuracy: 98.05%\n",
      "11\tValidation loss: 0.086287\tBest loss: 0.077042\tAccuracy: 98.08%\n",
      "12\tValidation loss: 0.087925\tBest loss: 0.077042\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.105439\tBest loss: 0.077042\tAccuracy: 97.81%\n",
      "14\tValidation loss: 0.076374\tBest loss: 0.076374\tAccuracy: 98.16%\n",
      "15\tValidation loss: 0.090988\tBest loss: 0.076374\tAccuracy: 97.89%\n",
      "16\tValidation loss: 0.097398\tBest loss: 0.076374\tAccuracy: 97.85%\n",
      "17\tValidation loss: 0.078982\tBest loss: 0.076374\tAccuracy: 97.97%\n",
      "18\tValidation loss: 0.087337\tBest loss: 0.076374\tAccuracy: 97.97%\n",
      "19\tValidation loss: 0.097042\tBest loss: 0.076374\tAccuracy: 98.01%\n",
      "20\tValidation loss: 0.080877\tBest loss: 0.076374\tAccuracy: 97.97%\n",
      "21\tValidation loss: 0.098259\tBest loss: 0.076374\tAccuracy: 97.85%\n",
      "22\tValidation loss: 0.079917\tBest loss: 0.076374\tAccuracy: 98.01%\n",
      "23\tValidation loss: 0.086188\tBest loss: 0.076374\tAccuracy: 97.97%\n",
      "24\tValidation loss: 0.092100\tBest loss: 0.076374\tAccuracy: 97.97%\n",
      "25\tValidation loss: 0.091762\tBest loss: 0.076374\tAccuracy: 98.01%\n",
      "26\tValidation loss: 0.073611\tBest loss: 0.073611\tAccuracy: 98.01%\n",
      "27\tValidation loss: 0.085476\tBest loss: 0.073611\tAccuracy: 97.69%\n",
      "28\tValidation loss: 0.086484\tBest loss: 0.073611\tAccuracy: 98.20%\n",
      "29\tValidation loss: 0.078721\tBest loss: 0.073611\tAccuracy: 98.20%\n",
      "30\tValidation loss: 0.080415\tBest loss: 0.073611\tAccuracy: 98.08%\n",
      "31\tValidation loss: 0.107698\tBest loss: 0.073611\tAccuracy: 97.89%\n",
      "32\tValidation loss: 0.098149\tBest loss: 0.073611\tAccuracy: 97.77%\n",
      "33\tValidation loss: 0.113995\tBest loss: 0.073611\tAccuracy: 97.89%\n",
      "34\tValidation loss: 0.068974\tBest loss: 0.068974\tAccuracy: 98.32%\n",
      "35\tValidation loss: 0.078459\tBest loss: 0.068974\tAccuracy: 98.01%\n",
      "36\tValidation loss: 0.106473\tBest loss: 0.068974\tAccuracy: 97.89%\n",
      "37\tValidation loss: 0.128066\tBest loss: 0.068974\tAccuracy: 97.34%\n",
      "38\tValidation loss: 0.141549\tBest loss: 0.068974\tAccuracy: 98.20%\n",
      "39\tValidation loss: 0.097715\tBest loss: 0.068974\tAccuracy: 97.85%\n",
      "40\tValidation loss: 0.124242\tBest loss: 0.068974\tAccuracy: 97.85%\n",
      "41\tValidation loss: 0.085057\tBest loss: 0.068974\tAccuracy: 98.12%\n",
      "42\tValidation loss: 0.122596\tBest loss: 0.068974\tAccuracy: 97.89%\n",
      "43\tValidation loss: 0.090535\tBest loss: 0.068974\tAccuracy: 97.69%\n",
      "44\tValidation loss: 0.087675\tBest loss: 0.068974\tAccuracy: 98.12%\n",
      "45\tValidation loss: 0.111559\tBest loss: 0.068974\tAccuracy: 97.97%\n",
      "46\tValidation loss: 0.077223\tBest loss: 0.068974\tAccuracy: 98.24%\n",
      "47\tValidation loss: 0.095805\tBest loss: 0.068974\tAccuracy: 98.05%\n",
      "48\tValidation loss: 0.103724\tBest loss: 0.068974\tAccuracy: 98.01%\n",
      "49\tValidation loss: 0.104389\tBest loss: 0.068974\tAccuracy: 98.05%\n",
      "50\tValidation loss: 0.100138\tBest loss: 0.068974\tAccuracy: 98.01%\n",
      "51\tValidation loss: 0.096708\tBest loss: 0.068974\tAccuracy: 98.28%\n",
      "52\tValidation loss: 0.093129\tBest loss: 0.068974\tAccuracy: 97.85%\n",
      "53\tValidation loss: 0.112871\tBest loss: 0.068974\tAccuracy: 97.54%\n",
      "54\tValidation loss: 0.114864\tBest loss: 0.068974\tAccuracy: 97.69%\n",
      "55\tValidation loss: 0.105246\tBest loss: 0.068974\tAccuracy: 97.85%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.149585\tBest loss: 0.149585\tAccuracy: 96.29%\n",
      "1\tValidation loss: 0.095796\tBest loss: 0.095796\tAccuracy: 97.46%\n",
      "2\tValidation loss: 0.117893\tBest loss: 0.095796\tAccuracy: 96.99%\n",
      "3\tValidation loss: 0.112725\tBest loss: 0.095796\tAccuracy: 96.52%\n",
      "4\tValidation loss: 0.083632\tBest loss: 0.083632\tAccuracy: 97.54%\n",
      "5\tValidation loss: 0.084327\tBest loss: 0.083632\tAccuracy: 97.38%\n",
      "6\tValidation loss: 0.095197\tBest loss: 0.083632\tAccuracy: 97.38%\n",
      "7\tValidation loss: 0.092096\tBest loss: 0.083632\tAccuracy: 97.54%\n",
      "8\tValidation loss: 0.086844\tBest loss: 0.083632\tAccuracy: 97.54%\n",
      "9\tValidation loss: 0.088525\tBest loss: 0.083632\tAccuracy: 97.93%\n",
      "10\tValidation loss: 0.074096\tBest loss: 0.074096\tAccuracy: 98.01%\n",
      "11\tValidation loss: 0.105153\tBest loss: 0.074096\tAccuracy: 97.69%\n",
      "12\tValidation loss: 0.091943\tBest loss: 0.074096\tAccuracy: 97.69%\n",
      "13\tValidation loss: 0.085016\tBest loss: 0.074096\tAccuracy: 97.97%\n",
      "14\tValidation loss: 0.111314\tBest loss: 0.074096\tAccuracy: 97.69%\n",
      "15\tValidation loss: 0.084999\tBest loss: 0.074096\tAccuracy: 97.81%\n",
      "16\tValidation loss: 0.073392\tBest loss: 0.073392\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.074545\tBest loss: 0.073392\tAccuracy: 98.12%\n",
      "18\tValidation loss: 0.088816\tBest loss: 0.073392\tAccuracy: 97.73%\n",
      "19\tValidation loss: 0.103732\tBest loss: 0.073392\tAccuracy: 98.05%\n",
      "20\tValidation loss: 0.084039\tBest loss: 0.073392\tAccuracy: 97.89%\n",
      "21\tValidation loss: 0.108531\tBest loss: 0.073392\tAccuracy: 98.08%\n",
      "22\tValidation loss: 0.082469\tBest loss: 0.073392\tAccuracy: 97.69%\n",
      "23\tValidation loss: 0.113337\tBest loss: 0.073392\tAccuracy: 98.01%\n",
      "24\tValidation loss: 0.119495\tBest loss: 0.073392\tAccuracy: 97.93%\n",
      "25\tValidation loss: 0.099772\tBest loss: 0.073392\tAccuracy: 97.73%\n",
      "26\tValidation loss: 0.083806\tBest loss: 0.073392\tAccuracy: 97.89%\n",
      "27\tValidation loss: 0.102345\tBest loss: 0.073392\tAccuracy: 97.81%\n",
      "28\tValidation loss: 0.089895\tBest loss: 0.073392\tAccuracy: 98.20%\n",
      "29\tValidation loss: 0.141350\tBest loss: 0.073392\tAccuracy: 98.05%\n",
      "30\tValidation loss: 0.171288\tBest loss: 0.073392\tAccuracy: 97.81%\n",
      "31\tValidation loss: 0.094826\tBest loss: 0.073392\tAccuracy: 98.20%\n",
      "32\tValidation loss: 0.107575\tBest loss: 0.073392\tAccuracy: 98.12%\n",
      "33\tValidation loss: 0.097164\tBest loss: 0.073392\tAccuracy: 98.12%\n",
      "34\tValidation loss: 0.104992\tBest loss: 0.073392\tAccuracy: 98.08%\n",
      "35\tValidation loss: 0.103090\tBest loss: 0.073392\tAccuracy: 97.73%\n",
      "36\tValidation loss: 0.098253\tBest loss: 0.073392\tAccuracy: 98.08%\n",
      "37\tValidation loss: 0.103508\tBest loss: 0.073392\tAccuracy: 97.69%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.119118\tBest loss: 0.119118\tAccuracy: 96.76%\n",
      "1\tValidation loss: 0.107815\tBest loss: 0.107815\tAccuracy: 96.83%\n",
      "2\tValidation loss: 0.110195\tBest loss: 0.107815\tAccuracy: 97.22%\n",
      "3\tValidation loss: 0.104981\tBest loss: 0.104981\tAccuracy: 96.79%\n",
      "4\tValidation loss: 0.103608\tBest loss: 0.103608\tAccuracy: 97.15%\n",
      "5\tValidation loss: 0.096661\tBest loss: 0.096661\tAccuracy: 97.19%\n",
      "6\tValidation loss: 0.097998\tBest loss: 0.096661\tAccuracy: 97.26%\n",
      "7\tValidation loss: 0.100841\tBest loss: 0.096661\tAccuracy: 97.34%\n",
      "8\tValidation loss: 0.098218\tBest loss: 0.096661\tAccuracy: 97.46%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\tValidation loss: 0.123141\tBest loss: 0.096661\tAccuracy: 97.42%\n",
      "10\tValidation loss: 0.091894\tBest loss: 0.091894\tAccuracy: 97.69%\n",
      "11\tValidation loss: 0.102535\tBest loss: 0.091894\tAccuracy: 97.46%\n",
      "12\tValidation loss: 0.086887\tBest loss: 0.086887\tAccuracy: 97.22%\n",
      "13\tValidation loss: 0.128858\tBest loss: 0.086887\tAccuracy: 97.50%\n",
      "14\tValidation loss: 0.085459\tBest loss: 0.085459\tAccuracy: 97.73%\n",
      "15\tValidation loss: 0.093410\tBest loss: 0.085459\tAccuracy: 97.11%\n",
      "16\tValidation loss: 0.107087\tBest loss: 0.085459\tAccuracy: 97.11%\n",
      "17\tValidation loss: 0.095439\tBest loss: 0.085459\tAccuracy: 97.15%\n",
      "18\tValidation loss: 0.099962\tBest loss: 0.085459\tAccuracy: 97.50%\n",
      "19\tValidation loss: 0.125496\tBest loss: 0.085459\tAccuracy: 97.03%\n",
      "20\tValidation loss: 0.117665\tBest loss: 0.085459\tAccuracy: 97.69%\n",
      "21\tValidation loss: 0.098031\tBest loss: 0.085459\tAccuracy: 97.54%\n",
      "22\tValidation loss: 0.154966\tBest loss: 0.085459\tAccuracy: 97.26%\n",
      "23\tValidation loss: 0.104618\tBest loss: 0.085459\tAccuracy: 97.22%\n",
      "24\tValidation loss: 0.090963\tBest loss: 0.085459\tAccuracy: 97.97%\n",
      "25\tValidation loss: 0.097077\tBest loss: 0.085459\tAccuracy: 98.08%\n",
      "26\tValidation loss: 0.114409\tBest loss: 0.085459\tAccuracy: 97.62%\n",
      "27\tValidation loss: 0.132012\tBest loss: 0.085459\tAccuracy: 97.34%\n",
      "28\tValidation loss: 0.115921\tBest loss: 0.085459\tAccuracy: 97.34%\n",
      "29\tValidation loss: 0.104119\tBest loss: 0.085459\tAccuracy: 97.62%\n",
      "30\tValidation loss: 0.116101\tBest loss: 0.085459\tAccuracy: 97.73%\n",
      "31\tValidation loss: 0.100416\tBest loss: 0.085459\tAccuracy: 97.46%\n",
      "32\tValidation loss: 0.118901\tBest loss: 0.085459\tAccuracy: 97.81%\n",
      "33\tValidation loss: 0.121015\tBest loss: 0.085459\tAccuracy: 97.62%\n",
      "34\tValidation loss: 0.117070\tBest loss: 0.085459\tAccuracy: 97.38%\n",
      "35\tValidation loss: 0.104191\tBest loss: 0.085459\tAccuracy: 97.22%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.137311\tBest loss: 0.137311\tAccuracy: 96.01%\n",
      "1\tValidation loss: 0.127086\tBest loss: 0.127086\tAccuracy: 96.36%\n",
      "2\tValidation loss: 0.072480\tBest loss: 0.072480\tAccuracy: 98.05%\n",
      "3\tValidation loss: 0.080365\tBest loss: 0.072480\tAccuracy: 97.97%\n",
      "4\tValidation loss: 0.096369\tBest loss: 0.072480\tAccuracy: 97.50%\n",
      "5\tValidation loss: 0.090838\tBest loss: 0.072480\tAccuracy: 98.16%\n",
      "6\tValidation loss: 0.104394\tBest loss: 0.072480\tAccuracy: 97.42%\n",
      "7\tValidation loss: 0.069775\tBest loss: 0.069775\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.069690\tBest loss: 0.069690\tAccuracy: 97.97%\n",
      "9\tValidation loss: 0.094893\tBest loss: 0.069690\tAccuracy: 97.81%\n",
      "10\tValidation loss: 0.085949\tBest loss: 0.069690\tAccuracy: 98.01%\n",
      "11\tValidation loss: 0.091262\tBest loss: 0.069690\tAccuracy: 97.65%\n",
      "12\tValidation loss: 0.091445\tBest loss: 0.069690\tAccuracy: 97.81%\n",
      "13\tValidation loss: 0.110647\tBest loss: 0.069690\tAccuracy: 97.89%\n",
      "14\tValidation loss: 0.087521\tBest loss: 0.069690\tAccuracy: 97.65%\n",
      "15\tValidation loss: 0.095321\tBest loss: 0.069690\tAccuracy: 98.01%\n",
      "16\tValidation loss: 0.106487\tBest loss: 0.069690\tAccuracy: 97.54%\n",
      "17\tValidation loss: 0.091342\tBest loss: 0.069690\tAccuracy: 97.81%\n",
      "18\tValidation loss: 0.103075\tBest loss: 0.069690\tAccuracy: 97.54%\n",
      "19\tValidation loss: 0.088027\tBest loss: 0.069690\tAccuracy: 97.62%\n",
      "20\tValidation loss: 0.118128\tBest loss: 0.069690\tAccuracy: 97.81%\n",
      "21\tValidation loss: 0.089614\tBest loss: 0.069690\tAccuracy: 97.97%\n",
      "22\tValidation loss: 0.089635\tBest loss: 0.069690\tAccuracy: 97.77%\n",
      "23\tValidation loss: 0.089293\tBest loss: 0.069690\tAccuracy: 97.93%\n",
      "24\tValidation loss: 0.098577\tBest loss: 0.069690\tAccuracy: 98.01%\n",
      "25\tValidation loss: 0.100263\tBest loss: 0.069690\tAccuracy: 97.50%\n",
      "26\tValidation loss: 0.085558\tBest loss: 0.069690\tAccuracy: 98.08%\n",
      "27\tValidation loss: 0.108377\tBest loss: 0.069690\tAccuracy: 98.01%\n",
      "28\tValidation loss: 0.082490\tBest loss: 0.069690\tAccuracy: 98.32%\n",
      "29\tValidation loss: 0.118672\tBest loss: 0.069690\tAccuracy: 98.12%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.083978\tBest loss: 0.083978\tAccuracy: 97.46%\n",
      "1\tValidation loss: 0.111926\tBest loss: 0.083978\tAccuracy: 97.11%\n",
      "2\tValidation loss: 0.086976\tBest loss: 0.083978\tAccuracy: 97.30%\n",
      "3\tValidation loss: 0.100073\tBest loss: 0.083978\tAccuracy: 97.22%\n",
      "4\tValidation loss: 0.086788\tBest loss: 0.083978\tAccuracy: 97.69%\n",
      "5\tValidation loss: 0.075805\tBest loss: 0.075805\tAccuracy: 97.50%\n",
      "6\tValidation loss: 0.082241\tBest loss: 0.075805\tAccuracy: 98.08%\n",
      "7\tValidation loss: 0.096507\tBest loss: 0.075805\tAccuracy: 97.89%\n",
      "8\tValidation loss: 0.092670\tBest loss: 0.075805\tAccuracy: 97.93%\n",
      "9\tValidation loss: 0.078723\tBest loss: 0.075805\tAccuracy: 97.97%\n",
      "10\tValidation loss: 0.108559\tBest loss: 0.075805\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.092986\tBest loss: 0.075805\tAccuracy: 98.05%\n",
      "12\tValidation loss: 0.074609\tBest loss: 0.074609\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.067012\tBest loss: 0.067012\tAccuracy: 98.08%\n",
      "14\tValidation loss: 0.108827\tBest loss: 0.067012\tAccuracy: 97.81%\n",
      "15\tValidation loss: 0.082837\tBest loss: 0.067012\tAccuracy: 97.69%\n",
      "16\tValidation loss: 0.089657\tBest loss: 0.067012\tAccuracy: 97.65%\n",
      "17\tValidation loss: 0.073443\tBest loss: 0.067012\tAccuracy: 98.24%\n",
      "18\tValidation loss: 0.094671\tBest loss: 0.067012\tAccuracy: 97.65%\n",
      "19\tValidation loss: 0.076942\tBest loss: 0.067012\tAccuracy: 97.97%\n",
      "20\tValidation loss: 0.084470\tBest loss: 0.067012\tAccuracy: 98.08%\n",
      "21\tValidation loss: 0.077866\tBest loss: 0.067012\tAccuracy: 97.85%\n",
      "22\tValidation loss: 0.087154\tBest loss: 0.067012\tAccuracy: 97.89%\n",
      "23\tValidation loss: 0.120360\tBest loss: 0.067012\tAccuracy: 97.93%\n",
      "24\tValidation loss: 0.089649\tBest loss: 0.067012\tAccuracy: 98.12%\n",
      "25\tValidation loss: 0.112394\tBest loss: 0.067012\tAccuracy: 97.50%\n",
      "26\tValidation loss: 0.116869\tBest loss: 0.067012\tAccuracy: 97.89%\n",
      "27\tValidation loss: 0.084209\tBest loss: 0.067012\tAccuracy: 98.16%\n",
      "28\tValidation loss: 0.079703\tBest loss: 0.067012\tAccuracy: 98.12%\n",
      "29\tValidation loss: 0.107145\tBest loss: 0.067012\tAccuracy: 98.20%\n",
      "30\tValidation loss: 0.078285\tBest loss: 0.067012\tAccuracy: 98.28%\n",
      "31\tValidation loss: 0.087339\tBest loss: 0.067012\tAccuracy: 98.20%\n",
      "32\tValidation loss: 0.076157\tBest loss: 0.067012\tAccuracy: 98.08%\n",
      "33\tValidation loss: 0.120216\tBest loss: 0.067012\tAccuracy: 97.97%\n",
      "34\tValidation loss: 0.091906\tBest loss: 0.067012\tAccuracy: 98.16%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.117970\tBest loss: 0.117970\tAccuracy: 96.56%\n",
      "1\tValidation loss: 0.124200\tBest loss: 0.117970\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.099494\tBest loss: 0.099494\tAccuracy: 97.73%\n",
      "3\tValidation loss: 0.087197\tBest loss: 0.087197\tAccuracy: 97.93%\n",
      "4\tValidation loss: 0.093727\tBest loss: 0.087197\tAccuracy: 97.65%\n",
      "5\tValidation loss: 0.082748\tBest loss: 0.082748\tAccuracy: 98.01%\n",
      "6\tValidation loss: 0.097725\tBest loss: 0.082748\tAccuracy: 97.58%\n",
      "7\tValidation loss: 0.094373\tBest loss: 0.082748\tAccuracy: 97.69%\n",
      "8\tValidation loss: 0.121676\tBest loss: 0.082748\tAccuracy: 97.62%\n",
      "9\tValidation loss: 0.091571\tBest loss: 0.082748\tAccuracy: 97.73%\n",
      "10\tValidation loss: 0.099723\tBest loss: 0.082748\tAccuracy: 97.77%\n",
      "11\tValidation loss: 0.088833\tBest loss: 0.082748\tAccuracy: 97.77%\n",
      "12\tValidation loss: 0.082406\tBest loss: 0.082406\tAccuracy: 97.97%\n",
      "13\tValidation loss: 0.088012\tBest loss: 0.082406\tAccuracy: 98.05%\n",
      "14\tValidation loss: 0.082628\tBest loss: 0.082406\tAccuracy: 97.89%\n",
      "15\tValidation loss: 0.084789\tBest loss: 0.082406\tAccuracy: 97.97%\n",
      "16\tValidation loss: 0.092825\tBest loss: 0.082406\tAccuracy: 98.20%\n",
      "17\tValidation loss: 0.082520\tBest loss: 0.082406\tAccuracy: 97.81%\n",
      "18\tValidation loss: 0.111470\tBest loss: 0.082406\tAccuracy: 98.01%\n",
      "19\tValidation loss: 0.122846\tBest loss: 0.082406\tAccuracy: 98.05%\n",
      "20\tValidation loss: 0.138107\tBest loss: 0.082406\tAccuracy: 97.89%\n",
      "21\tValidation loss: 0.080666\tBest loss: 0.080666\tAccuracy: 98.24%\n",
      "22\tValidation loss: 0.094882\tBest loss: 0.080666\tAccuracy: 98.08%\n",
      "23\tValidation loss: 0.098891\tBest loss: 0.080666\tAccuracy: 98.24%\n",
      "24\tValidation loss: 0.119901\tBest loss: 0.080666\tAccuracy: 97.34%\n",
      "25\tValidation loss: 0.094883\tBest loss: 0.080666\tAccuracy: 98.24%\n",
      "26\tValidation loss: 0.131451\tBest loss: 0.080666\tAccuracy: 97.93%\n",
      "27\tValidation loss: 0.104220\tBest loss: 0.080666\tAccuracy: 97.93%\n",
      "28\tValidation loss: 0.101988\tBest loss: 0.080666\tAccuracy: 97.93%\n",
      "29\tValidation loss: 0.094466\tBest loss: 0.080666\tAccuracy: 98.28%\n",
      "30\tValidation loss: 0.112070\tBest loss: 0.080666\tAccuracy: 98.05%\n",
      "31\tValidation loss: 0.110440\tBest loss: 0.080666\tAccuracy: 98.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\tValidation loss: 0.138448\tBest loss: 0.080666\tAccuracy: 97.73%\n",
      "33\tValidation loss: 0.112235\tBest loss: 0.080666\tAccuracy: 97.97%\n",
      "34\tValidation loss: 0.126586\tBest loss: 0.080666\tAccuracy: 97.85%\n",
      "35\tValidation loss: 0.199129\tBest loss: 0.080666\tAccuracy: 97.85%\n",
      "36\tValidation loss: 0.087656\tBest loss: 0.080666\tAccuracy: 98.16%\n",
      "37\tValidation loss: 0.094059\tBest loss: 0.080666\tAccuracy: 97.89%\n",
      "38\tValidation loss: 0.135952\tBest loss: 0.080666\tAccuracy: 97.69%\n",
      "39\tValidation loss: 0.129382\tBest loss: 0.080666\tAccuracy: 97.26%\n",
      "40\tValidation loss: 0.106241\tBest loss: 0.080666\tAccuracy: 97.89%\n",
      "41\tValidation loss: 0.128947\tBest loss: 0.080666\tAccuracy: 97.81%\n",
      "42\tValidation loss: 0.096874\tBest loss: 0.080666\tAccuracy: 97.93%\n",
      "Early stopping!\n",
      "0\tValidation loss: 0.089311\tBest loss: 0.089311\tAccuracy: 97.26%\n",
      "1\tValidation loss: 0.072946\tBest loss: 0.072946\tAccuracy: 98.01%\n",
      "2\tValidation loss: 0.081267\tBest loss: 0.072946\tAccuracy: 97.81%\n",
      "3\tValidation loss: 0.087614\tBest loss: 0.072946\tAccuracy: 97.81%\n",
      "4\tValidation loss: 0.085130\tBest loss: 0.072946\tAccuracy: 98.16%\n",
      "5\tValidation loss: 0.065336\tBest loss: 0.065336\tAccuracy: 98.28%\n",
      "6\tValidation loss: 0.078399\tBest loss: 0.065336\tAccuracy: 98.32%\n",
      "7\tValidation loss: 0.073985\tBest loss: 0.065336\tAccuracy: 97.89%\n",
      "8\tValidation loss: 0.075721\tBest loss: 0.065336\tAccuracy: 98.24%\n",
      "9\tValidation loss: 0.076962\tBest loss: 0.065336\tAccuracy: 98.28%\n",
      "10\tValidation loss: 0.072475\tBest loss: 0.065336\tAccuracy: 98.16%\n",
      "11\tValidation loss: 0.099465\tBest loss: 0.065336\tAccuracy: 97.85%\n",
      "12\tValidation loss: 0.066789\tBest loss: 0.065336\tAccuracy: 98.36%\n",
      "13\tValidation loss: 0.079340\tBest loss: 0.065336\tAccuracy: 97.97%\n",
      "14\tValidation loss: 0.105448\tBest loss: 0.065336\tAccuracy: 98.36%\n",
      "15\tValidation loss: 0.080105\tBest loss: 0.065336\tAccuracy: 98.20%\n",
      "16\tValidation loss: 0.116464\tBest loss: 0.065336\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.072809\tBest loss: 0.065336\tAccuracy: 98.20%\n",
      "18\tValidation loss: 0.099233\tBest loss: 0.065336\tAccuracy: 98.20%\n",
      "19\tValidation loss: 0.082565\tBest loss: 0.065336\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.082062\tBest loss: 0.065336\tAccuracy: 98.32%\n",
      "21\tValidation loss: 0.108100\tBest loss: 0.065336\tAccuracy: 98.16%\n",
      "22\tValidation loss: 0.075401\tBest loss: 0.065336\tAccuracy: 98.44%\n",
      "23\tValidation loss: 0.096299\tBest loss: 0.065336\tAccuracy: 98.40%\n",
      "24\tValidation loss: 0.089295\tBest loss: 0.065336\tAccuracy: 98.32%\n",
      "25\tValidation loss: 0.087646\tBest loss: 0.065336\tAccuracy: 98.12%\n",
      "26\tValidation loss: 0.132036\tBest loss: 0.065336\tAccuracy: 97.73%\n",
      "Early stopping!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-234-478cd9a319cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#removing samples with worst fitness and generating children\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0msorted_fitness_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerateChildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_fitness_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Dict values at generation no:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-232-bafa0eb62185>\u001b[0m in \u001b[0;36mgenerateChildren\u001b[1;34m(sorted_fitness_dict, X_train1, y_train1, X_valid1, y_valid1, X_test1, y_test1)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted_fitness_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted_fitness_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msorted_fitness_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0msorted_fitness_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "n_generations=3\n",
    "population=6\n",
    "\n",
    "param={'n_hidden_layers':[5,10,15,20],'n_neurons':[10,20,30,15],'learning_rate':[0.0001,0.001,0.01,0.1,1]}\n",
    "\n",
    "\n",
    "sorted_fitness_dict=getTop_N_Fit(population)\n",
    "for i in range(n_generations):\n",
    "    print ('generation no:',i)\n",
    "    \n",
    "    #generating random parameters\n",
    "    \n",
    "    \n",
    "    \n",
    "    #removing samples with worst fitness and generating children\n",
    "    sorted_fitness_dict=generateChildren(sorted_fitness_dict,X_train1, y_train1,X_valid1,y_valid1,X_test1,y_test1)\n",
    "    \n",
    "    print ('Dict values at generation no:',i)\n",
    "    print (sorted_fitness_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.968476357267951, [20, 10, 0.01]),\n",
       " 1: (0.96944930920412531, [20, 10, 0.01]),\n",
       " 2: (0.95699552442109359, [15, 10, 0.01]),\n",
       " 3: (0.94784977622105471, [15, 10, 0.1]),\n",
       " 4: (0.95991438022961662, [20, 10, 0.01]),\n",
       " 5: (0.96477913991048847, [15, 10, 0.01]),\n",
       " 6: (0.96069274177855613, [20, 10, 0.001]),\n",
       " 7: (0.95446584938704027, [20, 10, 0.01]),\n",
       " 8: (0.95894142829344231, [15, 20, 0.01]),\n",
       " 9: (0.95446584938704027, [15, 20, 0.01])}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted_fitness_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (0.97139521307647403, [15, 10, 0.01]),\n",
       " 1: (0.89686709476551862, [15, 30, 0.01]),\n",
       " 2: (0.9575792955827982, [20, 20, 0.1]),\n",
       " 3: (0.96030356100408643, [20, 20, 0.001]),\n",
       " 4: (0.9361743529869625, [15, 30, 0.01]),\n",
       " 5: (0.96575209184666277, [20, 20, 0.1])}"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted_fitness_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(sorted_fitness_dict.items(), key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-224-51da38181454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_fitness_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "OrderedDict(sorted(sorted_fitness_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.96575209184666277, [20, 20, 0.1])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_fitness_dict[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
